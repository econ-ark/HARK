{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HARK.frame import (\n",
    "    BackwardFrameReference,\n",
    "    ForwardFrameReference,\n",
    "    Frame,\n",
    "    FrameAgentType,\n",
    "    FrameModel,\n",
    "    draw_frame_model,\n",
    ")\n",
    "\n",
    "from HARK.distribution import combine_indep_dstns, add_discrete_outcome_constant_mean\n",
    "from HARK.distribution import (\n",
    "    IndexDistribution,\n",
    "    Lognormal,\n",
    "    MeanOneLogNormal,\n",
    "    Bernoulli,  # Random draws for simulating agents\n",
    ")\n",
    "\n",
    "from HARK.rewards import (\n",
    "    CRRAutility,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531d493",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "\n",
    "Refactor to separate model from simulator (AgentType)\n",
    "\n",
    "- [x] Separate FrameModel from FrameAgentType - AgentType has cycles parameter. FrameModel need not have it.\n",
    "- [x] Define Repeater transformation -- transforms FrameModel to be either explicitly infinite or to become finite cycled. Can take age-varying parameters here (and only here).\n",
    "- [x] FrameAgentType consumes a FrameModel, and runs simulations in HARK way\n",
    "- [ ] Further decouple FrameModel from FrameAgentType.\n",
    "  - [x] FrameModel should take parameters dictionary\n",
    "  - [x] Generalize simulation to access appropriate solution (transition_cNrm)\n",
    "  - [ ] FrameModel transition equations should not reference 'self' whiteboard\n",
    "  - [ ] FrameAgentType with an arbitrary well-formed FrameModel and solution should be able to forward-simulate\n",
    "  - [x] Replicate the ConsPortfolioFrameModel with new architecture.\n",
    "- [ ] Automated tests\n",
    "- [ ] Easier single variable target frames\n",
    "\n",
    "Solver as something that consumes and works with a FrameModel\n",
    "\n",
    "- [ ] Data structure for the solution of a model? -- A policy. (Look at Bellman library?)\n",
    "- [ ] Extract the key sequence of variables along which to pass value\n",
    "- [ ] Value-passing -- inverse function\n",
    "- [ ] Value-passing -- Inverse expected value -- for chance transitions\n",
    "- [ ] Policy updating --\n",
    "- [ ] Value backup\n",
    "\n",
    "Solvers for repeated FrameModels\n",
    "\n",
    "- [ ] Finite solver as composition of these tools\n",
    "- [ ] Infinite solver through use of tools to convergence\n",
    "\n",
    "Feed solution back to FrameAgentType\n",
    "\n",
    "- [ ] Build solution object a la HARK? Or ...\n",
    "- [ ] Adjust simulator so that it uses the new solution object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0e141",
   "metadata": {},
   "source": [
    "## Some simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5349e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_parameters = {}\n",
    "init_parameters[\"PermGroFac\"] = 1.05\n",
    "init_parameters[\"PermShkStd\"] = 1.5\n",
    "init_parameters[\"PermShkCount\"] = 5\n",
    "init_parameters[\"TranShkStd\"] = 3.0\n",
    "init_parameters[\"TranShkCount\"] = 5\n",
    "init_parameters[\"RiskyAvg\"] = 1.05\n",
    "init_parameters[\"RiskyStd\"] = 1.5\n",
    "init_parameters[\"RiskyCount\"] = 5\n",
    "init_parameters[\"Rfree\"] = 1.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: streamline this so it can draw the parameters from context\n",
    "def birth_aNrmNow(N, **context):\n",
    "    \"\"\"\n",
    "    Birth value for aNrmNow\n",
    "    \"\"\"\n",
    "    return Lognormal(\n",
    "        mu=context[\"aNrmInitMean\"],\n",
    "        sigma=context[\"aNrmInitStd\"],\n",
    "        ## TODO -- where does this seed come from? The AgentType?\n",
    "        seed=self.RNG.integers(0, 2**31 - 1),\n",
    "    ).draw(N)\n",
    "\n",
    "\n",
    "frame_model_A = FrameModel(\n",
    "    [\n",
    "        Frame((\"bNrm\",), (\"aNrm\",), transition=lambda Rfree, aNrm: Rfree * aNrm),\n",
    "        Frame((\"mNrm\",), (\"bNrm\", \"TranShk\"), transition=lambda bNrm: mNrm),\n",
    "        Frame((\"cNrm\"), (\"mNrm\",), control=True),\n",
    "        Frame(\n",
    "            (\"U\"),\n",
    "            (\"cNrm\", \"CRRA\"),  ## Note CRRA here is a parameter not a state var\n",
    "            transition=lambda cNrm, CRRA: (CRRAutility(cNrm, CRRA),),\n",
    "            reward=True,\n",
    "            context={\"CRRA\": 2.0},\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"aNrm\"),\n",
    "            (\"mNrm\", \"cNrm\"),\n",
    "            default={\"aNrm\": birth_aNrmNow},\n",
    "            transition=lambda mNrm, cNrm: (mNrm - cNrm,),\n",
    "        ),\n",
    "    ],\n",
    "    init_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab44a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_frame_model(frame_model_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(\n",
    "    list(frame_model_A.frames.var(\"bNrm\").parents.values())[0], BackwardFrameReference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_model_A.frames.var(\"aNrm\").children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_model_A.infinite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425cd0d",
   "metadata": {},
   "source": [
    "## Modifying the model\n",
    "\n",
    "-- To refactor to use standalone models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a87446",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_frame_model(frame_model_A.make_terminal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_model = frame_model_A.prepend(frame_model_A)\n",
    "draw_frame_model(double_model, figsize=(8, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_model = frame_model_A.make_terminal().prepend(frame_model_A)\n",
    "draw_frame_model(double_model, figsize=(8, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95361006",
   "metadata": {},
   "source": [
    "## repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_model = frame_model_A.repeat({\"bNrm\": {\"Rfree\": [1.01, 1.03, 1.02]}})\n",
    "draw_frame_model(repeat_model, figsize=(8, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_model.frames.var(\"bNrm_1\").context[\"Rfree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_model.frames.var(\"aNrm_2\").children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f196c",
   "metadata": {},
   "source": [
    "## Trying again at a solver ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1ea98",
   "metadata": {},
   "source": [
    "- [ ] Create grid of state values with a 'forward simulation' with dummy strategies\n",
    "- [ ] For each control variable, backwards:\n",
    "   - [ ] Create objective function $f$ summing:\n",
    "      - [ ] Direct rewards of (a, s)\n",
    "      - [ ] Weighted expected value of (a,s)\n",
    "  - [ ] Over a grid of state values in the control variable's scope:\n",
    "     - [ ] Find optimal a* for s given $f$\n",
    "  - [ ] Using (s, a*) pairs:\n",
    "     - [ ] Interpolate\n",
    "     - [ ] Into a decision rule\n",
    "- [ ] When all the decision rules are done, forward simulate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = frame_model_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decision_rule(control_frame: Frame):\n",
    "    # get scope\n",
    "    scope = control_frame.scope\n",
    "\n",
    "    # get objective function\n",
    "\n",
    "    # get grid over the scope\n",
    "\n",
    "    # get optimal action for each scope point given objective\n",
    "\n",
    "    # interpolate from (s, a*) into decision rule\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_value_function_from_reward_transition(transition, local_context):\n",
    "    def value_function(**parent_state):\n",
    "        inputs = parent_state.copy()\n",
    "        inputs.update(local_context)\n",
    "\n",
    "        return transition(**inputs)\n",
    "\n",
    "    return value_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(len(model.frames) - 1, 0, -1):\n",
    "    frame = model.frames.iloc(f)\n",
    "\n",
    "    if frame.reward:\n",
    "        frame.value = create_value_function_from_reward_transition(\n",
    "            frame.transition, frame.context\n",
    "        )\n",
    "\n",
    "    elif frame.control:\n",
    "        pass\n",
    "\n",
    "    elif len(frame.children) == 0:\n",
    "        # terminal chance node\n",
    "\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # intermediate state node\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.frames.iloc(3).context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.frames.iloc(3).value(**{\"cNrm\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0911b8",
   "metadata": {},
   "source": [
    "### pycid rules in parallel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761360bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def impute_random_decision(self, d: str) -> None:\n",
    "        \"\"\"Impute a random policy to the given decision node\"\"\"\n",
    "        try:\n",
    "            domain = self.model.domain[d]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"can't figure out domain for {d}, did you forget to specify DecisionDomain?\")\n",
    "        else:\n",
    "            self.model[d] = StochasticFunctionCPD(\n",
    "                d, lambda **pv: {outcome: 1 / len(domain) for outcome in domain}, self, domain, label=\"random_decision\"\n",
    "            )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def expected_utility(\n",
    "        self, context: Dict[str, Outcome], intervention: Dict[str, Outcome] = None, agent: AgentLabel = 0\n",
    "    ) -> float:\n",
    "        \"\"\"Compute the expected utility of an agent for a given context and optional intervention\n",
    "        For example:\n",
    "        cid = get_minimal_cid()\n",
    "        out = self.expected_utility({'D':1}) #TODO: give example that uses context\n",
    "        Parameters\n",
    "        ----------\n",
    "        context: Node values to condition upon. A dictionary mapping of node => value.\n",
    "        intervention: Interventions to apply. A dictionary mapping node => value.\n",
    "        agent: Evaluate the utility of this agent.\n",
    "        \"\"\"\n",
    "        return sum(self.expected_value(self.agent_utilities[agent], context, intervention=intervention))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471405c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def impute_optimal_decision(self, decision: str) -> None:\n",
    "        \"\"\"Impute an optimal policy to the given decision node\"\"\"\n",
    "        # self.add_cpds(random.choice(self.optimal_pure_decision_rules(d)))\n",
    "        self.impute_random_decision(decision)\n",
    "        domain = self.model.domain[decision]\n",
    "        utility_nodes = self.agent_utilities[self.decision_agent[decision]]\n",
    "        descendant_utility_nodes = list(set(utility_nodes).intersection(nx.descendants(self, decision)))\n",
    "        copy = self.copy()  # using a copy \"freezes\" the policy so it doesn't adapt to future interventions\n",
    "\n",
    "        @lru_cache(maxsize=1000)\n",
    "        def opt_policy(**parent_values: Outcome) -> Outcome:\n",
    "            eu = {}\n",
    "            for d in domain:\n",
    "                parent_values[decision] = d\n",
    "                eu[d] = sum(copy.expected_value(descendant_utility_nodes, parent_values))\n",
    "            return max(eu, key=eu.get)  # type: ignore\n",
    "\n",
    "        self.add_cpds(StochasticFunctionCPD(decision, opt_policy, self, domain=domain, label=\"opt\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47198b3",
   "metadata": {},
   "source": [
    "## Forward simulating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_agent_A = FrameAgentType(\n",
    "    frame_model_A, T_sim=5000, AgentCount=200, read_shocks=True, cycles=0\n",
    ")\n",
    "\n",
    "# frame_agent_A.solve()\n",
    "# frame_agent_A.track_vars += [\n",
    "#    \"mNrm\",\n",
    "#    \"cNrm\",\n",
    "#    \"aNrm\",\n",
    "#    \"bNrm\",\n",
    "#    'U'\n",
    "# ]\n",
    "\n",
    "# Doesn't work yet.\n",
    "# frame_agent_A.initialize_sim()\n",
    "# frame_agent_A.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Forward simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a4b6c",
   "metadata": {},
   "source": [
    "## Progressively more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641517a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe replace reference to init_portfolio to self.parameters?\n",
    "frame_model_B = FrameModel(\n",
    "    [\n",
    "        # todo : make an aggegrate value\n",
    "        Frame(\n",
    "            (\"PermShk\"),\n",
    "            None,\n",
    "            default={\n",
    "                \"PermShk\": 1.0\n",
    "            },  # maybe this is unnecessary because the shock gets sampled at t = 0\n",
    "            # this is discretized before it's sampled\n",
    "            transition=IndexDistribution(\n",
    "                Lognormal.from_mean_std,\n",
    "                {\n",
    "                    \"mean\": init_parameters[\"PermGroFac\"],\n",
    "                    \"std\": init_parameters[\"PermShkStd\"],\n",
    "                },\n",
    "            ).discretize(\n",
    "                init_parameters[\"PermShkCount\"], method=\"equiprobable\", tail_N=0\n",
    "            ),\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"TranShk\"),\n",
    "            None,\n",
    "            default={\n",
    "                \"TranShk\": 1.0\n",
    "            },  # maybe this is unnecessary because the shock gets sampled at t = 0\n",
    "            transition=IndexDistribution(\n",
    "                MeanOneLogNormal, {\"sigma\": init_parameters[\"TranShkStd\"]}\n",
    "            ).discretize(\n",
    "                init_parameters[\"TranShkCount\"], method=\"equiprobable\", tail_N=0\n",
    "            ),\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"Rport\"),\n",
    "            (\"Share\", \"Risky\", \"Rfree\"),\n",
    "            transition=lambda Share, Risky, Rfree: (\n",
    "                Share * Risky + (1.0 - Share) * Rfree,\n",
    "            ),\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"bNrm\",),\n",
    "            (\"aNrm\", \"Rport\", \"PermShk\"),\n",
    "            transition=lambda aNrm, Rport, PermShk: (Rport / PermShk) * aNrm,\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"mNrm\",),\n",
    "            (\"bNrm\", \"TranShk\"),\n",
    "            transition=lambda bNrm, TranShk: (bNrm + TranShk,),\n",
    "        ),\n",
    "        Frame((\"cNrm\"), (\"Adjust\", \"mNrm\", \"Share\"), control=True),\n",
    "        Frame(\n",
    "            (\"U\"),\n",
    "            (\n",
    "                \"cNrm\",\n",
    "                \"CRRA\",\n",
    "            ),  ## Note CRRA here is a parameter not a state var            transition = lambda self, cNrm, CRRA : (CRRAutility(cNrm, CRRA),),\n",
    "            reward=True,\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"aNrm\"),\n",
    "            (\"mNrm\", \"cNrm\"),\n",
    "            default={\"aNrm\": birth_aNrmNow},\n",
    "            transition=lambda mNrm, cNrm: (mNrm - cNrm,),\n",
    "        ),\n",
    "    ],\n",
    "    init_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c92f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_frame_model(frame_model_B)  # , dot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: streamline this so it can draw the parameters from context\n",
    "def birth_aNrmNow(self, N):\n",
    "    \"\"\"\n",
    "    Birth value for aNrmNow\n",
    "    \"\"\"\n",
    "    return Lognormal(\n",
    "        mu=self.aNrmInitMean,\n",
    "        sigma=self.aNrmInitStd,\n",
    "        seed=self.RNG.integers(0, 2**31 - 1),\n",
    "    ).draw(N)\n",
    "\n",
    "    # maybe replace reference to init_portfolio to self.parameters?\n",
    "\n",
    "\n",
    "frame_model_C = FrameModel(\n",
    "    [\n",
    "        # todo : make an aggegrate value\n",
    "        Frame(\n",
    "            (\"PermShk\"),\n",
    "            None,\n",
    "            default={\n",
    "                \"PermShk\": 1.0\n",
    "            },  # maybe this is unnecessary because the shock gets sampled at t = 0\n",
    "            # this is discretized before it's sampled\n",
    "            transition=IndexDistribution(\n",
    "                Lognormal.from_mean_std,\n",
    "                {\n",
    "                    \"mean\": init_parameters[\"PermGroFac\"],\n",
    "                    \"std\": init_parameters[\"PermShkStd\"],\n",
    "                },\n",
    "            ).discretize(\n",
    "                init_parameters[\"PermShkCount\"], method=\"equiprobable\", tail_N=0\n",
    "            ),\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"TranShk\"),\n",
    "            None,\n",
    "            default={\n",
    "                \"TranShk\": 1.0\n",
    "            },  # maybe this is unnecessary because the shock gets sampled at t = 0\n",
    "            transition=IndexDistribution(\n",
    "                MeanOneLogNormal, {\"sigma\": init_parameters[\"TranShkStd\"]}\n",
    "            ).discretize(\n",
    "                init_parameters[\"TranShkCount\"], method=\"equiprobable\", tail_N=0\n",
    "            ),\n",
    "        ),\n",
    "        Frame(  ## TODO: Handle Risky as an Aggregate value\n",
    "            (\"Risky\"),\n",
    "            None,\n",
    "            transition=IndexDistribution(\n",
    "                Lognormal.from_mean_std,\n",
    "                {\n",
    "                    \"mean\": init_parameters[\"RiskyAvg\"],\n",
    "                    \"std\": init_parameters[\"RiskyStd\"],\n",
    "                }\n",
    "                # seed=self.RNG.integers(0, 2 ** 31 - 1) : TODO: Seed logic\n",
    "            ).discretize(init_parameters[\"RiskyCount\"], method=\"equiprobable\"),\n",
    "            aggregate=True,\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"Rport\"),\n",
    "            (\"Share\", \"Risky\", \"Rfree\"),\n",
    "            transition=lambda Share, Risky, Rfree: (\n",
    "                Share * Risky + (1.0 - Share) * Rfree,\n",
    "            ),\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"bNrm\",),\n",
    "            (\"aNrm\", \"Rport\", \"PermShk\"),\n",
    "            transition=lambda aNrm, Rport, PermShk: (Rport / PermShk) * aNrm,\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"mNrm\",),\n",
    "            (\"bNrm\", \"TranShk\"),\n",
    "            transition=lambda bNrm, TranShk: (bNrm + TranShk,),\n",
    "        ),\n",
    "        Frame((\"Share\"), (\"Adjust\", \"mNrm\"), default={\"Share\": 0}, control=True),\n",
    "        Frame((\"cNrm\"), (\"Adjust\", \"mNrm\", \"Share\"), control=True),\n",
    "        Frame(\n",
    "            (\"U\"),\n",
    "            (\"cNrm\", \"CRRA\"),  ## Note CRRA here is a parameter not a state var\n",
    "            transition=lambda cNrm, CRRA: (CRRAutility(cNrm, CRRA),),\n",
    "            reward=True,\n",
    "        ),\n",
    "        Frame(\n",
    "            (\"aNrm\"),\n",
    "            (\"mNrm\", \"cNrm\"),\n",
    "            default={\"aNrm\": birth_aNrmNow},\n",
    "            transition=lambda mNrm, cNrm: (mNrm - cNrm,),\n",
    "        ),\n",
    "    ],\n",
    "    init_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_frame_model(frame_model_C, figsize=(8, 12))  # , dot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbf354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
