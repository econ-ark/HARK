{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec3f8e6",
   "metadata": {},
   "source": [
    "# Expressing Stochastic Optimization Problems with BARK\n",
    "\n",
    "_Notebook by Sebastian Benthall_\n",
    "\n",
    "This notebook is for working out the mathematical notation and API for expressing stochastic optimization problems in BARK.\n",
    "\n",
    "Solving stochastic optimization problems will be done in a separate notebook.\n",
    "\n",
    "As of 2023/05/03, this notebook does not have runnning Python code, as it is a revision of the earlier 'stage' based system in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360015d",
   "metadata": {},
   "source": [
    "## The basics of (Dynamic) Stochastic Optimization Problems\n",
    "\n",
    "### Optimization\n",
    "\n",
    "In an _optimization problem_, one seeks to maximize (or minimize) an objective function with respect to some control variable $x$. We can call the maximum attainable objective the _value_ $v$ of the problem.\n",
    "\n",
    "$$v = \\max_{x} r(x)$$\n",
    "\n",
    "There are many kinds of optimization problems and solution algorithms for solving them. Common ones include linear and concave programming.\n",
    "\n",
    "(Stachurski, 2009, and Ljungqvist and Sargent, 2018, both use $r$ for the reward function in the abstract.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f98ea",
   "metadata": {},
   "source": [
    "### Stochasticity\n",
    "\n",
    "An optimization is stochastic if the value of the objective function depends on the realization of a random variable. If $m \\sim P_M$ is a random variable over domain $M$, then we can optimize over the expected value of the objective function.\n",
    "\n",
    "$$v = \\max_{x} \\mathbb{E}[r(x, m]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4beaa",
   "metadata": {},
   "source": [
    "### Dynamism\n",
    "\n",
    "In a dynamic optimization problem, the optimization occurs over many steps of time. Some state $s$ is realized at each time step.\n",
    "\n",
    "$$V = \\max_x \\sum_{t = 0}^{T} \\beta^t r(s_t, x_t)$$\n",
    "\n",
    "Typically there is a relationship between the endogenous state values, such as $s_{t+1} = g(s_t, x_t)$. This sets up the definition of the time-dependent value function Bellman form:\n",
    "\n",
    "$$v_t(s_t) = \\max_{x_t} r(s_t, x_t) + \\beta v_{t+1}(g(s_t, x_t))$$\n",
    "\n",
    "This implies an optimal policy or decision rule:\n",
    "\n",
    "$$\\pi^*_t(s_t) = \\arg \\max_{x_t} r(s_t, x_t) + \\beta v_{t+1}(g(s_t, x_t))$$\n",
    "\n",
    "When $T = \\infty$, the problem is recursive and it is a \"dynamic programming\" problem. It is then subject to many interesting theorems about its optimality conditions, which support solution techniques that exploit that the Bellman operator is a contraction.\n",
    "\n",
    "When $T$ is finite, then the problem is not, technically speaking, a dynamic programming problem. However, under some general conditions it can be solved straightforwardly using backwards induction, i.e., solving for the value function of the last period, and then working backwards to $t = 0$. Some conditions of optimality in the dynamic programming case do not apply in the finite problem case.\n",
    "\n",
    "We are not focused on solution methods in this notebook.\n",
    "\n",
    "\n",
    "### Dynamic Stochastic Optimization Problems (DSOPs)\n",
    "\n",
    "Straightforwardly combining the above concepts,\n",
    "\n",
    "$$v_t(s_t) = \\max_{x_t} r(m_t, s_t, x_t) + \\beta \\mathbb{E} [v_{t+1}(g(m_t, s_t, x_t))]$$\n",
    "\n",
    "There is some variation in the abstract representation of DSOPs but for our purposes we will assume that $m_t$ and $m_{t+1}$ are always independent. An exogenous Markov process can be modeled with a combination of exogenous information $m_t$ and endogenous state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e3cc1",
   "metadata": {},
   "source": [
    "## Beyond the basics\n",
    "\n",
    "BARK is motivated by some use cases that go beyond the basics of dynamic stochastic optimization.\n",
    "\n",
    "### Lifecycle problems\n",
    "\n",
    "BARK is designed to support _structural changes over the agent lifecycle_. This means that the transition function $g_t$ and shocks $m_t$ can have structure that is not repeated over every period. This allows for much more expressivity in the finite problem case. This range of problems is sometimes referred to as _lifecycle problems_.\n",
    "\n",
    "**Example.** An agent faces structurally different choices before retirement. **TODO: Equations.**\n",
    "\n",
    "This is accomplished by decoupling the intra-period optimization problems from each other through the introduction of an end-of-period state $a_t$. Now, in the deterministic case $g: S \\times X \\rightarrow A$ :\n",
    "\n",
    "$$v_t(s_t) = \\max_{x_t} r(s_t, x_t) + \\beta v^{+}_{t}(g(s_t, x_t))$$\n",
    "\n",
    "Where $v^{+}_t$ is a value function over end-of-period states $a_t = g(s_t, x_t)$.\n",
    "\n",
    "Linking the periods together is done simply: $s_{t+1} = a_t$ and $v^{+}_t(a_t) = v^{+}_{t+1}(a_{t+1})$.\n",
    "\n",
    "If an agent experiences structural changes over time in an infinite horizon model, then these structural changes can be represented as sequential decomposition (see below). Typically, _lifecycle_ problems are finite.\n",
    "\n",
    "### Sequential decomposition\n",
    "\n",
    "BARK is also designed to support the _sequential decomposition_ of a time period's optimization problem into a series of simpler problems. Sequential decomposition has been shown to improve the performance of solution techniques by Lujan (2023). Here, the states, controls, and shocks for any period may be vector valued, and the problem for any one period can be defined in terms of partitions of these spaces.\n",
    "\n",
    "**Example.** An agent makes both a consumption and a portfolio allocation choice in the same period. These choices can be separated and made in sequence. **TODO: Equations.**\n",
    "\n",
    "**TODO: Some math here about partitioning and decomposition. To what extent can I build directly on Lujan (2023)?**\n",
    "\n",
    "**TODO: How does decomposition of period discount factors work? Especially with stochastic discounting.**\n",
    "\n",
    "### Dynamic discounting ('dyscounting')\n",
    "\n",
    "**SB: I'm open to new names of this. Generalized discounting?  Sargent and Stachurski (2023) discuss stochastic discounting, time-varying discounting, state-dependent discounting. I wouldn't try to publish 'dyscounting'.** \n",
    "\n",
    "BARK is also designed to support _dynamic discounting_. While typically dynamic programming problems use a constant discount factor, $\\beta$, there are cases where it is better to allow the generalized discount factor $\\beta_t(m_t, s_t, x_t)$ to be a function of the states. (Turning $\\beta$ into a function of state and controls is done by Sargent and Stachurski, 2023.)\n",
    "\n",
    "**Example.** In a normalized version of the household consumption problem, future value is discounted as a function of the permanent income shock. **TODO: Equations.**\n",
    "\n",
    "**Example.** A problem where probability of survival depends on allocation of resources towards health. **TODO: Equations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dada890",
   "metadata": {},
   "source": [
    "## New constructs for expressing DSOPs\n",
    "\n",
    "The \"B\" in \"BARK\" might stand for \"block\". The key architectural principle of BARK is that DSOPs can be composed out of blocks, where each block contains the information needed to solve a part of the larger problem.\n",
    "\n",
    "Currently there are just a few kinds of blocks in the BARK spec.\n",
    "\n",
    "The idea behind 'blocks' is that new kinds of blocks can be added for other problems. For example, an M-block could handle market aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27df916",
   "metadata": {},
   "source": [
    "### B-blocks\n",
    "\n",
    "A B-block is a representation of a static component of a dynamic stochastic optimization problem. They can include any of the following:\n",
    "\n",
    "* *Optimization*. The choice of an optimal value of a control variable to optimize an objective function, subject to constraints.\n",
    "* *Stochasticity*. An exogenous shock over which expectations must be taken ('prospecting').\n",
    "* *Dyscounting*. Discounting of future value based on current state, choices, and shocks.\n",
    "\n",
    "\n",
    "This sets up the optimization problem, given end-of-block value function $\\underline{v}$, which is outside of the block and the continuation value:\n",
    "\n",
    "$$v(s) = \\max_{x \\in \\Gamma(s, m)} \\mathbb{E}_M [r(s, m, x) + \\beta(s, m, x) \\underline{v}(g(s, m, x))] $$\n",
    "\n",
    "The forward simulation looks like:\n",
    " - Start in state $s$\n",
    " - Sample $m \\sim P_M$\n",
    " - Use decision rule $x = \\pi(s, m)$\n",
    " - Compute reward $r(s, m, x)$\n",
    " - Transition to post-state $a = g(s, m, x)$\n",
    "\n",
    "This can be solved in a variety of ways, depending on the conditions met by the specifics of the problem. These solution techniques will be discussed in a different notebook.\n",
    "\n",
    "#### Formal definition\n",
    "\n",
    "Formally, each B-block $B$ is a tuple $(\\vec{S}, P_\\vec{M}, \\vec{X}, \\Gamma, F, \\vec{Y}, T, \\beta)$, the agent:\n",
    " - begins in some beginning endogenous states $\\vec{s} \\in \\vec{S}$\n",
    " - experiences some exogeneous shocks $\\vec{m} \\in \\vec{M}$ according to probability distribution $P_\\vec{M}$\n",
    "     - Default: null $\\emptyset$\n",
    " - can choose some actions $\\vec{x} \\in \\vec{X}$\n",
    "     - Default: null $\\emptyset$\n",
    " - subject to constraints $\\Gamma: \\vec{S} \\times \\vec{M} \\rightarrow \\mathcal{P}(\\vec{X})$ (power set over the actions)\n",
    "     - For scalar actions, these may be expressed as upper and lower bounds, such that $\\Gamma_{lb} \\leq a \\leq \\Gamma_{ub}$:\n",
    "         - $\\Gamma_{ub}: \\vec{S} \\times \\vec{M} \\rightarrow \\mathbb{R}$\n",
    "         - $\\Gamma_{lb}: \\vec{S} \\times \\vec{M} \\rightarrow \\mathbb{R}$\n",
    "         - such that $\\Gamma(\\vec{s}, \\vec{m}) = [\\Gamma_{lb}(\\vec{x}, \\vec{k}), \\Gamma_{ub}(\\vec{x}, \\vec{k})]$\n",
    " - experience a reward $r: \\vec{S} \\times \\vec{M} \\times \\vec{X} \\rightarrow \\mathbb{R}$\n",
    " - together, these determine some post-states $\\vec{a} \\in \\vec{A}$ via...\n",
    " - a deterministic transition function $g: \\vec{S} \\times \\vec{M} \\times \\vec{X} \\rightarrow \\vec{A}$\n",
    "   - This is deterministic because shocks have been isolated to the beginning of the stage.\n",
    " - The agent has a discount factor $\\beta$ for future utility.\n",
    "     - This is often a constant, such as $\\beta$.\n",
    "     - but it can also be a function $\\beta: \\vec{S} \\times \\vec{M} \\times \\vec{X} \\rightarrow \\mathbb{R}$\n",
    "     - Default: $1$.\n",
    "\n",
    "CDC: What about a broader final transition $h(s, m, x, \\underline{v})$\n",
    "\n",
    "#### Schematized solution\n",
    "\n",
    "The definition of the B-Block suggests that most solutions for the represented sub-problem will have a similar structure. When the corresponding model element is the default value, an operation is trivial and can be accomplished with no computation. \n",
    "\n",
    "You start solving a block with $v^{+}$.\n",
    "\n",
    "\n",
    "| 'Move'  | Model element | Content  | Math |\n",
    "|---|---|---|---|\n",
    "| Expectation / Prospectation | Shock space $M$   | Computing expected values over shocks | $$v(s) = \\mathbb{E}_M [v^{\\sim}(s, m)]$$ |\n",
    "| Optimization  | Control space $X$ | Optimize control variable with respect to future value | $$v^{\\sim}(s, m) = \\max_x r(s, m, x) + v^{\\times}(s, m, x)$$ |\n",
    "| Dyscounting  | Discount function $\\beta$  | Reducing future value based on present conditions | $$v^{\\times}(s, m, x) = \\beta(s, m, x) \\underline{v}(g(s, m, x))$$ |\n",
    "\n",
    "\n",
    "**TODO: It would be better if the annotations on the value function matched the operations where it was used? But is $v^{\\times}$ intuitive for end-of-period value function?$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0fc85c",
   "metadata": {},
   "source": [
    "CDC points:\n",
    " - ~~Discounting happens between periods. Discounting should not normally happen on a stage or block.~~\n",
    " - ~~Question: is $v^{+}$ internal to the block, or outside of it?~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856f0e3",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "\n",
    "With a clear mathematical formalism, the information can be provided to a Python object with a simple interface like this:\n",
    "\n",
    "```\n",
    "consumption_block = BBlock(\n",
    "    transition = lambda x, k, a : {'a' : x['m'] - a['c']},\n",
    "    reward = lambda x, k, a : CRRA_utility(a['c'], CRRA),\n",
    "    inputs = ['m'], \n",
    "    actions = ['c'],\n",
    "    outputs = ['a'],\n",
    "    action_upper_bound = lambda x, k: (x['m'],) , \n",
    "    action_lower_bound = lambda x, k: (0.0,) , \n",
    "    discount = .96\n",
    ")\n",
    "```\n",
    "\n",
    "Or it can be parsed from a serialized configuration file like a DARK YAML.\n",
    "\n",
    "**TODO: More expressivitiy about the input, actions, and output _spaces_. See OSE implementation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee33bb",
   "metadata": {},
   "source": [
    "### P-blocks\n",
    "\n",
    "Roughly speaking, P-blocks are sequences of one or more B-blocks, ending with a `tick` (see below).\n",
    "\n",
    "We also introduce a simple operation, `twist`, to make it easier to reuse B-blocks.\n",
    "\n",
    "#### Ticks\n",
    "\n",
    "All P-blocks end with a a 'tick'.\n",
    "\n",
    "There is some ambiguity about the meaning of the the time indicator $t$ in DSOPS when we consider the full range of problems, including dynamic programming problems, finite lifecycle problems, and sequential decomposition. There may be more than one way to decompose a problem into subproblems, and where to put the delimiting increment of $t$ can be a modeler's choice.\n",
    "\n",
    "BARK addresses this by insisting that a P-block ends with a 'tick', which increments the model's time parameter $t$. This terminology is borrowed from NetLogo, in which `tick` measures discrete time in the global model. We will do more with `tick` as BARK expands into multi-agent systems with aggregation. At this point, it is mainly for accounting and consistency with traditional Economics modeling expecations.\n",
    "\n",
    "- Should ticks have discounting? Conflicting intuitions: (a) simplest possible tick; (b) wanting to discount\n",
    "- Does the 'tick' block manage information flow between periods and if so how?\n",
    "\n",
    "#### Twists\n",
    "\n",
    "We would like to support the user's reuse of B-block definitions. For example, a B-block can be defined in software code, or with a configuration file, and composed with other B-blocks developed by other users. This should facilitate reproducible research and collaboration in Economics, which is the overall goal.\n",
    "\n",
    "Because there is no guarantee that two B-blocks $B_1$ and $B_2$ will use the same naming conventions, we allow for a simple `twist` operation, $s_{t+1} = w(a_t)$, which can be introduced as connective tissue between two B-blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b213f1",
   "metadata": {},
   "source": [
    "### As a formal grammar\n",
    "\n",
    "The construction of DSOPs out of blocks can be thought up as a simple formal grammar a la Chomsky (1957).\n",
    "\n",
    "Consider the following:\n",
    "- Nonterminal symbols:\n",
    "  - $\\Omega$ - a partial DSOP with no starting condition.\n",
    "  - $P_t$ - a P-block including the final tick\n",
    "  - $P$ - a P-block stripped of the final tick\n",
    "  - $B_w$ - a B-block that may or may not include a twist\n",
    "- Terminal symbols:\n",
    "  - $B$ - A B-block\n",
    "  - $w$ - a 'twist' allowing for the realigning/renaming of variables $a_t = s_{t+1}$\n",
    "  - $\\tau$ - a 'tick' denoting the end of period and the incrementing of the $t$ counter.\n",
    "  - $\\alpha$ - a symbol denoting that the overall problem is repeating/recursive.\n",
    "- Production rules:\n",
    "  - $\\Omega_\\alpha \\rightarrow \\alpha \\Omega | \\Omega$, Either the problem is recursive, or it is not \n",
    "  - $\\Omega \\rightarrow P_t\\Omega$ - you can always add a period to a \n",
    "  - $P_t \\rightarrow P\\tau$, ticks are mandatory to end periods\n",
    "  - $P \\rightarrow B_w | B_wP$\n",
    "  - $B_w \\rightarrow Bw | B$ twists are optional\n",
    "- $\\Omega_\\alpha$ - a DSOP ('starting symbol'), may or may not be recursive.\n",
    "\n",
    "This grammar can be expanded in future versions of BARK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1925a047",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "Ljungqvist, L. and Sargent, T.J., 2018. Recursive macroeconomic theory. MIT press.\n",
    "\n",
    "Lujan, A. 2023. _Dissertation Title_.\n",
    "\n",
    "Sargent and Stachurski, 2023. Dynamic Programming, Volume 1: Foundations.\n",
    "\n",
    "Stachurski, J., 2009. Economic dynamics: theory and computation. MIT Press.\n",
    "\n",
    "Stokey, Nancy, Robert Lucas, and Prescott, Edward C. (1989) Recursive Methods in Economic Dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8730318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hark-env",
   "language": "python",
   "name": "hark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
