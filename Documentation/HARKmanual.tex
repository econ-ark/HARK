% !TeX spellcheck = en_GB

\documentclass[12pt,titlepage,letterpaper]{econtex}
\usepackage{econtexSetup}\usepackage{econtexShortcuts}
\usepackage{graphicx}
\usepackage{hyperref}
\newcommand{\E}{\mathbb{E}}

\begin{document}
\title{\LARGE A User's Guide for HARK: \\ Heterogeneous Agents Resources and toolKit}

\date{\normalsize{\today}}

\maketitle

\begin{center}
\includegraphics{UserGuidePic.pdf}
\end{center}

\thispagestyle{empty}
\newpage

\tableofcontents

\newpage

\section{Introduction}

If you are willing to risk some mild psychological trauma, conjure to mind your first experience of hand-coding a structural economic model.  Your clunky effort probably built on legacy code provided by an adviser or colleague -- which itself came from who-knows-what apocryphal sources.  Efforts to combine elements from one model with those from another were likely frustrated by the ``Tower of Babel'' problem: Code from one source could not ``speak'' to code from another without your own intermediation as a translator, possibly between two unfamiliar languages and aided only by oracular comments that, at best, made sense only in the context of other (now missing) code.

After months of effort, you may have had the character-improving experience of proudly explaining to your adviser that not only had you grafted two ideas together, you also found a trick that speeded the solution by an order of magnitude, only to be told that your breathtaking insight had been understood for many years, as reflected in an appendix to a 2008 paper; or, worse, your discovery was something that ``everybody knows'' but did not exist at all in published form!

Learning by doing has value, but only within limits.  We do not require young drivers to design an internal combustion engine before driving a car, nor must graduate students write their own matrix inversion algorithms before running an OLS regression.  

In recent years, considerable progress has been made in addressing these kinds of problems in many areas of economic modeling.  Macroeconomists using representative agent models can ship Dynare model files to each other; reduced form econometricians can choose from a host of econometric packages.  But modelers whose questions require explicit structural modeling involving nontrivial kinds of heterogeneity (that is, heterogeneity that cannot simply be aggregated away) are mostly still stuck in the bad old days.

The ultimate goal of the HARK project is to fix these problems.  Specifically, our aim is to produce an open source repository of highly modular, easily interoperable code for solving, simulating, and estimating dynamic economic models with heterogeneous agents.\footnote{By ``heterogeneous,'' we mean both \textit{ex ante} and \textit{ex post} heterogeneity: agents differ before anything in the model has ``happened''; and agents will experience different stochastic events during the model.}  Further, we seek to establish (with input from the community) standards for the description and specification of objects like discrete approximations to continuous distributions and interpolated function approximations, so that numeric methods can be quickly swapped without ugly ``patching.''

We hope that HARK will make it much easier and faster for researchers to develop solution and estimation methods for new models.  The open source nature of HARK will make it easier for other researchers to audit and verify new models and methods, and to collaborate on correcting deficiencies when found.  As HARK expands to include more canonical models and more tools and utilities, we can all spend less time managing numerical minutiae and more time fretting about identification arguments and data accuracy.

\subsection{Getting Started}

If you want to get started using HARK right away, this section provides a very easy quickstart guide for getting HARK up and running on your computer in just a few minutes.  More information can be found in the \texttt{README.txt} file in the HARK repository (step 4), but the quick version for those who want to jump right in:

\begin{enumerate}
\item \textbf{Download Anaconda:} Go to \href{https://www.continuum.io/downloads}{https://www.continuum.io/downloads} and download Anaconda for your operating system; be sure to get the version for Python 2.7.

\item \textbf{Install Anaconda:} Follow the easy instructions on that page to install Anaconda.

\item \textbf{Add extra packages:} (optional) If you want to use HARK's multithreading feature, you need to add two packages that aren't part of the default Anaconda distribution.  Simply open a command prompt and do \texttt{conda install joblib} and \texttt{conda install dill}, accepting defaults to install.

\item \textbf{Download HARK:} Go to \href{https://github.com/econ-ark/HARK}{https://github.com/econ-ark/HARK}, the home of the HARK repository.  Click on the lime green button labeled ``Clone or download'' toward the upper right of the main panel, and select ``Download ZIP''.\footnote{This is the fastest way to get HARK running on a computer.  Later, if you want to make your own contributions to HARK by adding code (or fixing ours!), you'll need to clone the repository on your computer.  See section 5.2 for more.}

\item \textbf{Unzip HARK:} Unpack the \texttt{HARK.zip} file using any archive utility, like \href{http://www.peazip.org/}{Peazip}.  Put the files anywhere you'd like, maintaining the internal directory structure.

\item \textbf{Run Spyder:} Open a command prompt and do \texttt{spyder}.  Spyder is an interactive development environment (IDE) for iPython, a slightly prettier, more interactive flavor of Python.

\item \textbf{Open a HARK module:} Go to the directory where you put HARK and open any file with the \texttt{.py} extension; we recommend \texttt{/ConsumptionSaving/ConsIndShockModel.py}.

\item \textbf{Run the module:} Click on the green arrow ``play'' button toward the right side of the toolbar of icons at the top of the Spyder window (accept defaults if a dialogue box pops up).  Congratulations! HARK is now up and running on your computer.
\end{enumerate}

If you followed our recommendation to try \texttt{/ConsumptionSaving/ConsIndShockModel.py}, you should see graphical representations of the solution to a few consumption-saving models with idiosyncratic shocks to permanent and transitory income (see OTHER DOCUMENT for details of these models).  If you chose a different module, you might get some examples of some other model, results of a structural estimation, or just a polite message that this particular module doesn't do much on its own.  See the \texttt{README.txt} for a full list of modules from which you can expect non-trivial output.

\subsection{Structure of HARK}

HARK is written in Python, an object-oriented programming language that has experienced increasing popularity in the scientific community in the past several years.  A significant reason for the adoption of Python is the \texttt{numpy} and \texttt{scipy} packages, which offer a wide array of mathematical and statistical functions and tools; HARK makes liberal use of these libraries.  Python's object-oriented nature allows models in HARK to be easily extended: more complex models can inherit functions and methods from more fundamental ``parent'' models, eliminating the need to reproduce or repurpose code.

As implied in the previous section, we strongly encourage HARK users to use the Anaconda distribution of Python, which includes all commonly used mathematical and scientific packages, an interactive development environment for iPython (Spyder), and a package manager that allows users to quickly install or update packages not included in the default distribution (conda).

Python modules (files with the \texttt{.py} extension) in HARK can generally be categorized into three types: tools, models, and applications.  \textbf{Tool modules} contain functions and classes with general purpose tools that have no inherent ``economic content'', but that can be used in many economic models as building blocks or utilities; they could plausibly be useful in non-economic settings.  Tools might include functions for data analysis (e.g.\ calculating Lorenz shares from data, or constructing a non-parametric kernel regression), functions to create and manipulate discrete approximations to continuous distributions, or classes for constructing interpolated approximations to non-parametric functions.  Tool modules generally reside in HARK's root directory and have names like \texttt{HARKsimulation} and \texttt{HARKinterpolation}; they do not necessarily do anything when run.

\textbf{Model modules} specify particular economic models, including classes to represent agents in the model (and the ``market structure'' in which they interact) and functions for solving the ``one period problem'' of those models.  For example, \texttt{ConsIndShockModel.py} concerns consumption-saving models in which agents have CRRA utility over consumption and face idiosyncratic shocks to permanent and transitory income.  The module includes a class for representing ``types'' of consumers, along with functions for solving (several flavors of) the one period consumption-saving problem.  When run, model modules might demonstrate example specifications of their models, filling in the model parameters with arbitrary values.  When \texttt{ConsIndShockModel.py} is run, it specifies an infinite horizon consumer with a particular discount factor, permanent income growth rate, coefficient of relative risk aversion (etc), who faces lognormal shocks to permanent and transitory income each period with a particular standard deviation; it then solves this consumer's problem and graphically displays the results.\footnote{Running \texttt{ConsIndShockModel.py} also demonstrates other variations of the consumption-saving problem, but their description is omitted here for brevity.}  Model modules generally have \texttt{Model} in their name.

\textbf{Application modules} use tool and model modules to solve, simulate, and/or estimate economic models \textit{for a particular purpose}.  While tool modules have no particular economic content and model modules describe entire classes of economic models, applications are uses of a model for some research purpose.  For example, \texttt{/SolvingMicroDSOPs/StructEstimation.py} uses a consumption-saving model from \texttt{ConsIndShockModel.py}, calibrating it with age-dependent sequences of permanent income growth, survival probabilities, and the standard deviation of income shocks (etc); it then estimates the coefficient of relative risk aversion and shifter for an age-varying sequence of discount factors that best fits simulated wealth profiles to empirical data from the Survey of Consumer Finance.  A particular application might have multiple modules associated with it, all of which generally reside in one directory.

\subsection{Other Resources}

In the incredibly unlikely scenario in which this document does not fill all of the gaps in your knowledge and answer any questions you might have while reading it, here is a collection of potentially helpful other resources.

\begin{itemize}

\item A \href{https://docs.python.org/2.7/tutorial/}{tutorial on Python 2.7}, straight from the source.

\item \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{Wikipedia article on object-oriented programming}, not the subject of an edit war.

\item \href{http://quant-econ.net/}{QuantEcon}, a collection of lectures on quantitative economic modeling from a couple of no-name economists, which in no way influenced HARK.

\item A \href{https://www.atlassian.com/git/tutorials/}{tutorial on git}, the repository management and tracking system used by the HARK project, created by Linus Torvalds.

\item A \href{https://guides.github.com/activities/hello-world/}{tutorial on GitHub}, a website that provides a useful framework for git that makes it significantly more user-friendly, despised by Linus Torvalds.

\item \href{https://en.wikipedia.org/wiki/Linus_Torvalds}{Wikipedia article on Linus Torvalds}, just in case.

\item The \href{http://www.numpy.org/}{homepage for NumPy}, a numerical package extensively used by HARK.

\end{itemize}

\newpage

\section{General Purpose Tools}

HARK's root directory contains six tool modules,\footnote{The ``taxonomy'' of these modules is in flux; the functions described here could be combined into fewer modules or further divided by purpose.} each containing a variety of functions and classes that can be used in many economic models-- or even for mathematical purposes that have nothing to do with economics.  Some of the tool modules are very sparely populated at this time, while others are quite large.  We expect that all of these modules will grow considerably in the near future, as new tools are ``low hanging fruit'' for contribution to the project.\footnote{That is, as the foundational, building-block elements of HARK, new tools are not difficult to program and do not require extensive integration with many moving parts.}

\subsection{HARKcore}

A key goal of the project is to create modularity and interoperability between models, making them easy to combine, adapt, and extend.  To this end, the \texttt{HARKcore} module specifies a framework for economic models in HARK, creating a common structure for them on two levels that can be called ``microeconomic'' and ``macroeconomic''.

Microeconomic models in HARK use the \texttt{AgentType} class to represent the agents with an intertemporal optimization problem.  Each model in HARK specifies a subclass of \texttt{AgentType}; an instance of the subclass represents agents who are \textit{ex ante} homogeneous-- they have common values for all parameters that describe the problem.  For example, \texttt{ConsIndShockModel} specifies the \texttt{ConsumerType} class, which has methods specific to consumption-saving models with idiosyncratic shocks to income; an instance of the class might represent all consumers who have a CRRA of 3, discount factor of 0.98, etc.  The \texttt{AgentType} class has a \texttt{solve} method that acts as a ``universal microeconomic solver'' for any properly formatted model, making it easier to set up a new model and to combine elements from different models; the solver is intended to encompass any model that can be framed as a sequence of one period problems.  For a more complete description, see section 3.

Macroeconomic models in HARK use the \texttt{Market} class to represent a market (or other aggregator) that combines the actions, states, and/or shocks (generally, outcomes) of individual agents in the model into aggregate outcomes that are ``passed back'' to the agents.  For example, the market in a consumption-saving model might combine the individual asset holdings of all agents in the market to generate aggregate capital in the economy, yielding the interest rate on assets (as the marginal product of capital); the individual agents then learn the aggregate capital level and interest rate, conditioning their next action on this information.  Objects that microeconomic agents treat as exogenous when solving (or simulating) their model are thus endogenous at the macroeconomic level. Like \texttt{AgentType}, the \texttt{Market} class also has a \texttt{solve} method, which seeks out a dynamic general equilibrium: a ``rule'' governing the dynamic evolution of macroeconomic objects such that if agents believe this rule and act accordingly, then their collective actions generate a sequence of macroeconomic actions that justify the belief in that rule.  For a more complete description, see section 4.

Beyond the model frameworks, \texttt{HARKcore} also defines a ``supersuperclass'' called \texttt{HARKobject}.  When solving a dynamic microeconomic model with an infinite horizon (or searching for a dynamic general equilibrium), it is often required to consider whether two solutions are sufficiently close to each other to warrant stopping the process (i.e.\ approximate convergence).  It is thus necessary to calculate the ``distance'' between two solutions, so HARK specifies that classes should have a \texttt{distance} method that takes a single input and returns a non-negative value representing the (generally dimensionless) distance between the object in question and the input to the method.  As a convenient default, \texttt{HARKobject} provides a ``universal distance metric'' that should be useful in many contexts.\footnote{Roughly speaking, the universal distance metric is a recursive supnorm, returning the largest distance between two instances, among attributes named in \texttt{distance\_criteria}.  Those attributes might be complex objects themselves rather than real numbers, generating a recursive call to the universal distance metric.}  When defining a new subclass of \texttt{HARKobject}, the user simply defines the attribute \texttt{distance\_criteria} as a list of strings naming the attributes of the class that should be compared when calculating the distance between two instances of that class.  For example, the class \texttt{ConsumerSolution} has \texttt{distance\_criteria = ['cFunc']}, indicating that only the consumption function attribute of the solution matters when comparing the distance between two instances of \texttt{ConsumerSolution}.

\subsection{HARKutilities}

The \texttt{HARKutilities} module carries a double meaning in its name, as it contains both utility functions (and their derivatives, inverses, and combinations thereof) in the economic modeling sense as well as utilities in the sense of general tools.  Utility functions included at this time are constant relative risk aversion and constant absolute risk aversion.  Other functions in \texttt{HARKutilities} include some data manipulation tools (e.g.\ for calculating an average of data conditional on being within a percentile range of different data), functions for constructing discrete state space grids, convenience functions for retrieving information about functions, and basic plotting tools using \texttt{matplotlib.pyplot}.

The module also includes functions for constructing discrete approximations to continuous distributions (e.g.\ \texttt{approxLognormal()} to approximate a log-normal distribution) as well as manipulating these representations (e.g.\ appending one outcome to an existing distribution, or combining independent univariate distributions into one multivariate distribution).  As a convention in HARK, continuous distributions are reframed as finite discrete distributions when solving models; an $N$-dimensional random variable is formatted as a length $N+1$ list of 1D arrays, with the first element representing event probabilities and all other elements are realizations of the $N$ component RVs.  This both simplifies solution methods (reducing numeric integrals to simple dot products) and allows users to easily test whether their chosen degree of discretization yields a sufficient approximation to the full distribution.  See LINK TO SPHINX for full documentation.

\subsection{HARKinterpolation}

The \texttt{HARKinterpolation} module defines classes for representing interpolated function approximations.  Interpolation methods in HARK all inherit from a superclass such as \texttt{HARKinterpolator1D} or \texttt{HARKinterpolator2D}, wrapper classes that ensures interoperability across interpolation methods.  For example, \texttt{HARKinterpolator1D} specifies the methods \texttt{\_\_call\_\_} and \texttt{derivative} to accept an arbitrary array as an input and return an identically shaped array with the interpolated function evaluated at the values in the array or its first derivative, respectively.  However, these methods do little on their own, merely reshaping arrays and referring to the \texttt{\_evaluate} and \texttt{\_der} methods, which are \textit{not actually defined in} \texttt{HARKinterpolator1D}.  Each subclass of \texttt{HARKinterpolator1D} specifies their own implementation of \texttt{\_evaluate} and \texttt{\_der} particular to that interpolation method, accepting and returning only 1D arrays.  In this way, subclasses of \texttt{HARKinterpolator1D} are easily interchangeable with each other, as all methods that the user interacts with are identical, varying only by ``internal'' methods.

When evaluating a stopping criterion for an infinite horizon problem, it is often necessary to know the ``distance'' between functions generated by successive iterations of a solution procedure.  To this end, each interpolator class in HARK must define a \texttt{distance} method that takes as an input another instance of the same class and returns a non-negative real number representing the ``distance'' between the two.  As each of the \texttt{HARKinterpolatorXD} classes inherits from \texttt{HARKobject}, all interpolator classes have the default ``universal'' distance method; the user must simply list the names of the relevant attributes in the attribute \texttt{distance\_criteria} of the class.

Interpolation methods currently implemented in HARK include (multi)linear interpolation up to 4D, 1D cubic spline interpolation, (multi)linear interpolation over 1D interpolations (up to 4D total), (multi)linear interpolation over 2D interpolations (up to 4D total), linear interpolation over 3D interpolations, 2D curvilinear interpolation over irregular grids, and a 1D ``lower envelope'' interpolator.  See LINK TO SPHINX for full documentation.

\subsection{HARKsimulation}

The \texttt{HARKsimulation} module provides tools for generating simulated data or shocks for post-solution use of models.  Currently implemented distributions include normal, lognormal, Weibull (including exponential), uniform, Bernoulli, and discrete.  As an example of their use, these tools are used in the consumption-saving models of \texttt{ConsIndShockModel.py} to simulate permanent and transitory income shocks as well as unemployment events.  See LINK TO SPHINX for full documentation.

\subsection{HARKestimation}

Methods for optimizing an objective function for the purposes of estimating a model can be found in \texttt{HARKestimation}.  As of this writing, the implementation includes only minimization by the Nelder-Mead simplex method, minimization by a derivative-free Powell method variant, and two small tools for resampling data (i.e.\ for a bootstrap); the minimizers are merely convenience wrappers (with result reporting) for optimizers included in \texttt{scipy.optimize}.  Future functionality will include more robust global search methods, including genetic algorithms, simulated annealing, and differential evolution.  See LINK TO SPHINX for full documentation.

\subsection{HARKparallel}

By default, processes in Python are single-threaded, using only a single CPU core.  The \texttt{HARKparallel} module provides basic tools for using multiple CPU cores simultaneously, with minimal effort.\footnote{\texttt{HARKparallel} uses two packages that aren't included in the default distribution of Anaconda: \texttt{joblib} and \texttt{dill}; see step 3 of the instructions in section 1.1 for how to install them.}  In particular, it provides the function \texttt{multiThreadCommands}, which takes two arguments: a list of \texttt{AgentType}s and a list of commands as strings; each command should be a method of the \texttt{AgentType}s.  The function simply distributes the \texttt{AgentType}s across threads on different cores and executes each command in order, returning no output (the \texttt{AgentType}s themselves are changed by running the commands).  Equivalent results would be achieved by simply looping over each type and running each method in the list.  Indeed, \texttt{HARKparallel} also has a function called \texttt{multiThreadCommandsFake} that does just that, with identical syntax to \texttt{multiThreadCommands}; multithreading in HARK can thus be easily turned on and off.\footnote{In the future, \texttt{HARKparallel} might be absorbed into \texttt{HARKcore} and \texttt{HARKestimation}, particularly if \texttt{joblib} and \texttt{dill} become part of the standard Anaconda distribution.}  The module also has functions for a parallel implementation of the Nelder-Mead simplex algorithm, as described in Wiswall and Lee (2011). See LINK TO SPHINX for full documentation.

\section{Microeconomics: the AgentType Class}

The core of our microeconomic dynamic optimization framework is a flexible object-oriented representation of economic agents.  The \texttt{HARKcore} module defines a superclass called \texttt{AgentType}; each model defines a subclass of \texttt{AgentType}, specifying additional model-specific features and methods while inheriting the methods of the superclass.  Most importantly, the method \texttt{solve} acts as a ``universal solver'' applicable to any (properly formatted) discrete time model.  This section describes the format of an instance of \texttt{AgentType} as it defines a dynamic microeconomic problem;\footnote{Each instance of \texttt{AgentType} represents an \textit{ex ante} heterogeneous ``type'' of agent; \textit{ex post} heterogeneity is achieved by simulating many agents of the same type, each of whom receives a unique sequence of shocks.}

\subsection{Attributes of an AgentType}

A discrete time model in our framework is characterized by a sequence of ``periods'' that the agent will experience.  A well-formed instance of \texttt{AgentType} includes the following attributes:
\begin{itemize}
\item \texttt{solveOnePeriod}: A function pointer, or a list of function pointers, representing the solution method for a single period of the agent's problem.  The inputs passed to a \texttt{solveOnePeriod} function include all data that characterize the agent's problem in that period, including the solution to the subsequent period's problem (designated as \texttt{solution\_next}).  The output of these functions is a single \texttt{Solution} object, which can be passed to the solver for the previous period.

\item \texttt{time\_inv}: A list of strings containing all of the variable names that are passed to at least one function in \texttt{solveOnePeriod} but do \textit{not} vary across periods.  Each of these variables resides in a correspondingly named attribute of the \texttt{AgentType} instance.

\item \texttt{time\_vary}: A list of strings naming the attributes of this instance that vary across periods.  Each of these attributes is a list of period-specific values, which should be of the same length.  If the solution method varies across periods, then \texttt{'solveOnePeriod'} is an element of \texttt{time\_vary}.\footnote{\texttt{time\_vary} may include attributes that are never used by a function in \texttt{solveOnePeriod}.  Most saliently, the attribute \texttt{solution} is time-varying but is not used to solve individual periods.}

\item \texttt{solution\_terminal}: An object representing the solution to the ``terminal'' period of the model.  This might represent a known trivial solution that does not require numeric methods, the solution to some previously solved ``next phase'' of the model, a scrap value function, or an initial guess of the solution to an infinite horizon model.

\item \texttt{pseudo\_terminal}: A Boolean flag indicating that \texttt{solution\_terminal} is not a proper terminal period solution (rather an initial guess, ``next phase'' solution, or scrap value) and should not be reported as part of the model's solution.

\item \texttt{cycles}: A non-negative integer indicating the number of times the agent will experience the sequence of periods in the problem.  For example, \texttt{cycles = 1} means that the sequence of periods is analogous to a lifecycle model, experienced once from beginning to end; \texttt{cycles = 2} means that the agent experiences the sequence twice, with the first period in the sequence following the last.  An infinite horizon problem in which the sequence of periods repeats indefinitely is indicated with \texttt{cycles = 0}.

\item \texttt{tolerance}: A positive real number indicating convergence tolerance, representing the maximum acceptable ``distance'' between successive cycle solutions in an infinite horizon model; it is irrelevant when \texttt{cycles > 0}.  As the distance metric on the space of solutions is model-specific, the value of \texttt{tolerance} is generally dimensionless.

\item \texttt{time\_flow}: A Boolean flag indicating the direction that time is ``flowing.''  When \texttt{True}, the variables listed in \texttt{time\_vary} are listed in ordinary chronological order, with index 0 being the first period; when \texttt{False}, these lists are in reverse chronological order, with index 0 holding the last period.
\end{itemize}

An instance of \texttt{AgentType} also has the attributes named in \texttt{time\_vary} and \texttt{time\_inv}, and may have other attributes that are not included in either (e.g.\  values not used in the model solution, but instead to construct objects used in the solution).

\subsection{A Universal Solver}

When an instance of \texttt{AgentType} invokes its \texttt{solve} method, the solution to the agent's problem is stored in the attribute \texttt{solution}.  The solution is computed by recursively solving the sequence of periods defined by the variables listed in \texttt{time\_vary} and \texttt{time\_inv} using the functions in \texttt{solveOnePeriod}.  The time-varying inputs are updated each period, including the successive period's solution as \texttt{solution\_next}; the same values of time invariant inputs in \texttt{time\_inv} are passed to the solver in every period.  The first call to \texttt{solveOnePeriod} uses \texttt{solution\_terminal} as \texttt{solution\_next}.  In a finite horizon problem, the sequence of periods is solved \texttt{cycles} times over; in an infinite horizon problem, the sequence of periods is solved until the solutions of successive cycles have a ``distance'' of less than \texttt{tolerance}.

The output from a function in \texttt{solveOnePeriod} is an instance of a model-specific solution class.  The attributes of a solution to one period of a problem might include behavioral functions, (marginal) value functions, and other variables characterizing the result.  Each solution class must have a method called \texttt{distance()}, which returns the ``distance'' between itself and another instance of the same solution class, so as to define convergence as a stopping criterion; for many models, this will be the ``distance'' between a behavioral or value function in the solutions.  If the solution class is defined as a subclass of \texttt{HARKobject}, it automatically inherits the default \texttt{distance} method, so that the user must only list the relevant object attributes in \texttt{distance\_criteria}.

Our universal solver is written in a very general way that should be applicable to any discrete time optimization problem-- because Python is so flexible in defining objects, the time-varying inputs for each period can take any form.  Indeed, the solver does no ``real work'' itself, but merely provides a structure for describing models in the HARK framework, allowing interoperability among current and future modules. 

\subsection{The Flow of Time and Other Methods}

Because dynamic optimization problems are solved recursively in our framework, it is natural to list time-varying values in reverse chronological order-- the \texttt{solve()} method loops over the values in each time-varying list in the same direction that a human would read them.  When simulating agents after the solution has been obtained, however, it is much more convenient for time-varying parameters to be listed in ordinary chronological order-- the direction in which they will be experienced by simulated agents.  To allow the user to set the order in which ``time is flowing'' for an instance of \texttt{AgentType}, the HARK framework includes functionality to easily change ordering of time-varying values.

The attribute \texttt{time\_flow} is \texttt{True} if variables are listed in ordinary chronological order and \texttt{False} otherwise.  \texttt{AgentType} has the following methods for manipulating time:
\begin{itemize}
\item \texttt{timeReport()}: Prints to screen a description of the direction that time is flowing, for interactive convenience and as a reminder of the functionality.

\item \texttt{timeFlip()}: Flips the direction of time.  Each attribute listed in \texttt{time\_vary} is reversed in place, and the value of \texttt{time\_flow} is toggled.

\item \texttt{timeFwd()}: Sets the direction of time to ordinary chronological order.

\item \texttt{timeRev()}: Sets the direction of time to reverse chronological order.
\end{itemize}

These methods are invoked to more conveniently access time-varying objects.  When a new time-varying attribute is added, its name should be appended to \texttt{time\_vary}, particularly if its values are used in the solution of the model (or is part of the solution itself).  For example, the \texttt{solve()} method automatically adds the string \texttt{'solution'} to \texttt{time\_vary} if it is not already present.  Note that attributes listed in \texttt{time\_vary} \textit{must} be lists if \texttt{solve()} or \texttt{timeFlip()} are used.  Some values that could be considered ``time varying'' but are never used to solve the model are more conveniently represented as a \texttt{numpy.array} object (e.g.\ \ the history of a state or control variable from a simulation); because the \texttt{numpy.array} class does not have a \texttt{reverse()} method, these attributes should not be listed in \texttt{time\_vary}.

The base \texttt{AgentType} is sparsely defined, as most ``real'' methods will be application-specific.  One final method bears mentioning: the \texttt{\_\_call\_\_()} method points to \texttt{assignParameters()}, a convenience method for adding or adjusting attributes (inherited from \texttt{HARKobject}).  These methods take any number of keyword arguments, so that code can be parsimoniously written as, for example, \texttt{AgentInstance(attribute1 = value1, attribute2 = value2)}.  Using Python's dictionary capabilities, many attributes can be conveniently set with minimal code.

ADD PARAGRAPH ABOUT PRESOLVE AND POSTSOLVE

\subsection{Sample Model: Perfect Foresight Consumption-Saving}

To provide a concrete example of how the \texttt{AgentType} class works, consider the very simple case of a perfect foresight consumption-saving model.  The agent has time separably additive CRRA preferences over consumption, discounting future utility at a constant rate; he receives a particular stream of labor income each period, and knows the interest rate on assets that he holds from one period to the next.  His decision about how much to consume in a particular period can be expressed in Bellman form as:

\begin{eqnarray*}
V_t(M_t) &=& \max_{C_t} \utilFunc(C_t) + \beta \PLives_t \E [V_{t+1}(M_{t+1}) ], \\
A_t &=& M_t - C_t, \\
M_{t+1} &=& \Rfree A_t + Y_{t+1}, \\
Y_{t+1} &=& \Gamma_{t+1} Y_t, \\
\utilFunc(C) &=& \frac{C^{1-\CRRA}}{1-\CRRA}.
\end{eqnarray*}
An agent's problem is thus characterized by values of $\CRRA$, $\Rfree$,  and $\beta$ plus sequences of survival probabilities $\PLives_t$ and income growth factors $\Gamma_t$ for $t=0,\cdots,T$.  This problem has an analytical solution for both the value function and the consumption function.

The \texttt{ConsIndShockModel} module defines the class \texttt{ConsumerType} as a subclass of \texttt{AgentType} and provides solver functions for several variations of a consumption-saving model, including the perfect foresight problem.\footnote{As the name implies, the module is mostly concerned with models with idiosyncratic shocks to income.}  A HARK user could specify and solve a ten period perfect foresight model with the following commands:

\vspace{0.25cm}

\noindent \texttt{MyConsumer = ConsumerType(time\_flow=True, cycles=1)}

\noindent \texttt{MyConsumer.CRRA = 2.7}

\noindent \texttt{MyConsumer.Rfree = 1.03}

\noindent \texttt{MyConsumer.DiscFac = 0.98}

\noindent \texttt{MyConsumer.LivPrb = [0.99,0.98,0.97,0.96,0.95,0.94,0.93,0.92,0.91,0.90]}

\noindent \texttt{MyConsumer.PermGroFac = [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]}

\noindent \texttt{MyConsumer.solveOnePeriod = solvePerfForesight}

\noindent \texttt{MyConsumer.solve()}

\vspace{0.25cm}

The first line makes a new instance of \texttt{ConsumerType}, specifying that time is currently ``flowing'' forward\footnote{This is relevant for the intepretation of the time-varying inputs \texttt{LivPrb} and \texttt{PermGroFac}.} and that the sequence of periods happens exactly once.  The next five lines set the time invariant (\texttt{CRRA}, \texttt{Rfree}, \texttt{DiscFac}) and time varying parameters (\texttt{LivPrb}, \texttt{PermGroFac}), and the following one sets the appropriate one period solver.\footnote{By default, a new instance of \texttt{ConsumerType} has a solver for a model with risky income.}  After running the \texttt{solve} method, \texttt{MyConsumer} will have an attribute called \texttt{solution}, which will be a list with eleven \texttt{ConsumerSolution} objects, representing the period-by-period solution to the model.\footnote{The last element of \texttt{solution} represents the terminal period solution, where the agent consumes all available resources because there is no future.}  Each \texttt{ConsumerSolution} has several attributes:
\begin{itemize}
\item \texttt{cFunc}: Optimal consumption function for this period as a function of (normalized) market resources $m_t = M_t/Y_t$. Can be called like any other function: \texttt{MyConsumer.solution[0].cFunc(5)} evaluates the consumption function at $m_t = 5$.

\item \texttt{vFunc}: Value function (over market resources $m_t$); can be evaluated like \texttt{cFunc}.

\item \texttt{mNrmMin}: Minimum value of normalized market resources $m_t$ such that \texttt{cFunc} and \texttt{vFunc} are defined. 

\item \texttt{hNrm}: Normalized human wealth-- the PDV of future income (ignoring mortality) divided by current period income $Y_t$.

\item \texttt{MPC}: The constant marginal propensity to consume (linear consumption function).

\end{itemize}

To solve a version of this problem in which the sequence of ten periods happens three times (yielding a \texttt{solution} attribute with thirty-one elements), the user can do:

\vspace{0.25cm}

\noindent \texttt{MyConsumer(cycles = 3)}

\noindent \texttt{MyConsumer.solve()}

\vspace{0.25cm}

To solve an infinite horizon problem in which the agent experiences the same one period problem indefinitely, the user can do:

\vspace{0.25cm}

\noindent \texttt{OtherConsumer = ConsumerType(cycles=0, CRRA=3.5, Rfree=1.02, DiscFac=0.95,}

\texttt{LivPrb = [0.99], PermGroFac = [1.01], solveOnePeriod = solvePerfForesight}

\noindent \texttt{OtherConsumer.solve()}

\vspace{0.25cm}

This instance is specified as being infinite horizon by setting \texttt{cycles=0}.  Note that the time-varying inputs are still specified as (one element) lists, even though they take on the same value in every period; this is because an infinite horizon model might consist of a multi-period sequence repeated indefinitely, rather than just one repeated period.  The \texttt{solution} attribute of \texttt{OtherConsumer} will be a list containing one instance of \texttt{ConsumerSolution}, representing the solution to every period of the model.

\section{Macroeconomics: the Market Class}

The modeling framework of \texttt{AgentType} is deemed ``microeconomic'' because it pertains only to the dynamic optimization problem of agents, treating all inputs of the problem as exogenously fixed.  In what we label as ``macroeconomic'' models, some of the inputs for the microeconomic models are endogenously determined by the collective states and controls of agents in the model.  In a dynamic general equilibrium, there must be consistency between agents' beliefs about these macroeconomic objects, their individual behavior, and the realizations of the macroeconomic objects that result from individual choices.

The \texttt{Market} class in \texttt{HARKcore} provides a framework for such macroeconomic models, with a \texttt{solve} method that searches for a dynamic general equilibrium.  An instance of \texttt{Market} includes a list of \texttt{AgentType}s that compose the economy, a methods converting microeconomic outcomes (states, controls, and/or shocks) into macroeconomic outcomes, and a method for converting a history or sequence of macroeconomic outcomes into a new ``dynamic rule'' for agents to believe.  Agents treat the dynamic rule as an input to their microeconomic problem, conditioning their optimal policy functions on it.  A dynamic general equilibrium is a fixed point dynamic rule: when agents act optimally while believing the equilibrium rule, their individual actions generate a macroeconomic history consistent with the equilibrium rule.

\subsection{Down on the Farm}

The \texttt{Market} class uses a farming metaphor to conceptualize the process for generating a history of macroeconomic outcomes in a model.  Suppose all \texttt{AgentTypes} in the economy believe in some dynamic rule (i.e.\ the rule is stored as attributes of each \texttt{AgentType}, which directly or indirectly enters their dynamic optimization problem), and that they have each found the solution to their microeconomic model using their \texttt{solve} method.  Further, the macroeconomic and microeconomic states have been reset to some initial orientation.

To generate a history of macroeconomic outcomes, the \texttt{Market} repeatedly loops over the following steps a set number of times:
\begin{enumerate}
\item \texttt{sow}: Distribute the macroeconomic state variables to all \texttt{AgentType}s in the market.

\item \texttt{cultivate}: Each \texttt{AgentType} executes their \texttt{marketAction} method, likely corresponding to simulating one period of the microeconomic model.

\item \texttt{reap}: Microeconomic outcomes are gathered from each \texttt{AgentType} in the market.

\item \texttt{mill}: Data gathered by \texttt{reap} is processed into new macroeconomic states according to some ``aggregate market process''.

\item \texttt{store}: Relevant macroeconomic states are added to a running history of outcomes.
\end{enumerate}
This procedure is conducted by the \texttt{makeHistory} method of \texttt{Market} as a subroutine of its \texttt{solve} method.  After making histories of the relevant macroeconomic variables, the market then executes its \texttt{calcDynamics} function with the macroeconomic history as inputs, generating a new dynamic rule to distribute to the \texttt{AgentType}s in the market.  The process then begins again, with the agents solving their updated microeconomic models given the new dynamic rule; the \texttt{solve} loop continues until the ``distance'' between successive dynamic rules is sufficiently small.

\subsection{Attributes of a Market}

To specify a complete instance of \texttt{Market}, the user should give it the following attributes:\footnote{For some purposes, it might be useful to specify a subclass of \texttt{Market}, defining \texttt{millRule} and/or \texttt{calcDynamics} as methods rather than functions.}
\begin{itemize}
\item \texttt{agents}: A list of \texttt{AgentType}s, representing the agents in the market.  Each element in \texttt{agents} represents on \textit{ex ante} heterogeneous type; each type could have many \textit{ex post} heterogeneous agents.

\item \texttt{sow\_vars}: A list of strings naming variables that output from the aggregate market process, representing the macroeconomic outcomes.  These variables will be distributed to the texttt{agents} in the \texttt{sow} step.

\item \texttt{reap\_vars}: A list of strings naming variables to be collected from the \texttt{agents} in the \texttt{reap} step, to be used as inputs for the aggregate market process.

\item \texttt{const\_vars}: A list of strings naming variables used by the aggregate market process but \textit{do not} come from \texttt{agents}; they are constant or come from the \texttt{Market} itself.

\item \texttt{track\_vars}: A list of strings naming variables generated by the aggregate market process that should be tracked as a history, to be used when calculating a new dynamic rule.  Usually a subset of \texttt{sow\_vars}.

\item \texttt{dyn\_vars}: A list of strings naming the variables that constitute a dynamic rule.  These will be stored as attributes of the \texttt{agents} whenever a new rule is calculated.

\item \texttt{millRule}: A function for the ``aggregate market process'', transforming microeconomic outcomes into macroeconomic outcomes.  Its inputs are named in \texttt{reap\_vars} and \texttt{const\_vars}, and it returns a single object with attributes named in \texttt{sow\_vars} and/or \texttt{track\_vars}.  Can be defined as a method of a subclass of \texttt{Market}.

\item \texttt{calcDynamics}: A function that generates a new dynamic rule from a history of macroeconomic outcomes.  Its inputs are named in \texttt{track\_vars}, and it returns a single object with attributes named in \texttt{dyn\_vars}.

\item \texttt{act\_T}: The number of times that the \texttt{makeHistory} method should execute the ``farming loop'' when generating a new macroeconomic history.

\item \texttt{tolerance}: The minimum acceptable ``distance'' between successive dynamic rules produced by \texttt{calcDynamics} to constitute a sufficiently converged solution.
\end{itemize}

Further, each \texttt{AgentType} in \texttt{agents} must have two methods not necessary for microeconomic models; neither takes any input (except \texttt{self}):
\begin{itemize}
\item \texttt{marketAction}: The microeconomic process to be run in the \texttt{cultivate} step.  Likely uses the new macroeconomic outcomes named in \texttt{sow\_vars}; should store new values of relevant microeconomic outcomes in the attributes (of \texttt{self}) named in \texttt{reap\_vars}.

\item \texttt{reset}: Reset, initialize, or prepare for a new ``farming loop'' to generate a macroeconomic history.  Might reset its internal random number generator, set initial state varibles, clear personal histories, etc.
\end{itemize}

When solving macroeconomic models in HARK, the user should also define classes to represent the output from the aggregate market process in \texttt{millRule} and for the model-specific dynamic rule.  The latter should have a \texttt{distance} method to test for solution convergence; if the class inherits from \texttt{HARKobject}, the user need only list relevant attributes in \texttt{distance\_criteria}.

\subsection{Sample Model: FashionVictim}

To illustrate the \texttt{Market} class, consider a simple example in the emerging economic subfield of aesthemetrics, the \texttt{FashionVictimModel}.\footnote{This model is inspired by the paper ``The hipster effect: When anticonformists all look the same'' by Jonathan Touboul.}\footnote{For a more traditional macroeconomic model, the \texttt{cstwMPC} module includes a consumption-saving model with both idiosyncratic and aggregate shocks, in which individual asset holdings are aggregated into total productive capital, endogenizing the (dynamic) interest and wage rate.}  This module defines a subclass of \texttt{AgentType} called \texttt{FashionVictimType}.  Each period, fashion victims make a binary choice of style $s$: to dress as a jock (0) or punk (1).  They receive utility directly from the outfit they wear and as a function of the proportion of the population who \textit{just wore} the same style; they also pay switching costs ($c_{pj}$,$c_{jp}$) if they change styles rather than keep the same as the previous period.  Moreover, they receive an idiosyncratic T1EV preference shock to each style in each period.  Defining the population punk proportion as $p$ and the conformity utility function as $f:[0,1]\rightarrow \mathbb{R}$, the current period utility function is thus:
\begin{equation*}
u(s_t;s_{t-1},p_t) = s_t f(p_t) + (1-s_t) f(1-p_t) + s_t U_p + (1-s_t) U_j - c_{pj} s_{t-1}(1-s_t) - c_{jp}(1-s_{t-1})s_t.
\end{equation*}

Fashion victims are forward looking and discount future utility at a constant rate of $\beta$ per period.  To simplify the analysis, we assume they believe that the population punk proportion in the next period is a linear function of the punk proportion in the current period, subject to a uniformly distributed shock.  No restrictions are put on the function $f$; fashion victims might be conformists who like to dress the same as others ($f'(p) > 0$) or hipsters who like to style themselves in the minority ($f'(p) < 0$).\footnote{In practice, $f$ is parameterized as the beta distribution for convenience.}  A fashion victim's problem can be written in Bellman form as:
\begin{equation*}
V(s_{t-1},p_t) = \E \left[ \max_{s_t \in \{0,1\}} u(s_t;s_{t-1},p_t) + \eta_{s_t} + \beta \E \left[ V(s_t,p_{t+1}) \right] \right], 
\end{equation*}
\begin{equation*}
p_{t+1} = a p_t + b + \pi_{t+1}, \qquad \pi_{t+1} \sim U[-w,w], \qquad \eta_0,\eta_1 \sim T1EV.
\end{equation*}

An instance of \texttt{FashionVictimType} is thus characterized by values of $U_p$, $U_j$, $c_{pj}$, $c_{jp}$ and a function $f$, as well as beliefs about $p_{t+1}$ as a function of $p_t$ (summarized by slope $a$, intercept $b$, and uniform shock width $w$).  Given this information, a \texttt{FashionVictimType}'s infinite horizon microeconomic model can be solved by backward induction in a few lines; the ``one period solver'' is given by \texttt{solveFashion}.  However, while individual agents treat the dynamics of $p_t$ as exogenous, they are in fact endogenously determined by the actions of all the fashion victims in the market.\footnote{The market might consist of agents all of the same type, or might have several types with \textit{ex ante} heterogeneity.}  A dynamic general equilibrium of the ``macroeconomic fashion model'' is thus characterized by a triple of $(a,b,w)$ such that when fashion victims believe in this ``punk evolution rule'' and act optimally, their collective fashion choices exhibit this same rule when the model is simulated.

The search for a dynamic general equilibrium is implemented in HARK's \texttt{Market} class with the following definitions:

\vspace{0.25cm}

\noindent \texttt{sow\_vars      = ['pNow']} (macroeconomic outcome is $p_t$)

\noindent \texttt{reap\_vars     = ['sNow']} (microeconomic outcomes are $s_t$ for many agents)

\noindent \texttt{track\_vars    = ['pNow']} (must track history of $p_t$)

\noindent \texttt{dyn\_vars      = ['pNextSlope','pNextIntercept','pNextWidth']} (dynamic rule $(a,b,w)$)

\noindent \texttt{millRule      = calcPunkProp} (aggregate process: average the style choices of all agents)

\noindent \texttt{calcDynamics  = calcFashionEvoFunc} (calculate new $(a,b,w)$ with autoregression of $p_t$)

\noindent \texttt{act\_T         = 1000} (simulate 1000 periods of the fashion market)

\noindent \texttt{tolerance     = 0.01} (terminate solution when $(a,b,w)$ changes by less than 0.01)

\vspace{0.25cm}

The \texttt{agents} attribute has a list of 22 \texttt{FashionVictimType}s, which vary in their values of $U_p$ and $U_j$, and their $f$ functions.  The \texttt{marketAction} method of \texttt{FashionVictimType} simulates one period of the microeconomic model: each agent receives style preference shocks $\eta_0$ and $\eta_1$, sees the current proportion of punks $p_t$ (sown to them as \texttt{pNow}), and chooses which style to wear, storing it in the binary array \texttt{sNow}, an attribute of \texttt{self}.

The \texttt{millRule} for this market is extremely simple: it flattens the list of binary arrays of individual style choices (gathered in the \texttt{reap} step) and averages them into a new value of $p_t$, to be tracked as a history and \texttt{sow}n back to the \texttt{agents} to begin the cycle again.  Once a history of 1000 values of $p_t$ has been generated with the \texttt{makeHistory} method, we can calculate a new dynamic fashion rule with \texttt{calcFashionEvoFunc} by regressing $p_t$ on $p_{t-1}$, approximating $w$ as twice the standard deviation of prediction errors.\footnote{This is an arbitrary way to calculate $w$, but accuracy is not important in a silly example.}  The new fashion rule is an instance of the simple \text{FashionEvoFunc} class, whose only methods are inherited from \texttt{HARKobject}.

When the \texttt{solve} method is run, the solver successively solves each agent's microeconomic problem, runs the \texttt{makeHistory} method to generate a 1000 period history of $p_t$, and calculates a new punk evolution rule based on this history; the solver terminates when consecutive rules differ by less than 0.01 in any dimension.

\section{Contributing to HARK}

blah blah

\subsection{What Does HARK Want?}

blah blah

\subsection{Git and GitHub}

blah blah

\subsection{Submitting Code}

blah blah

\subsection{Naming Conventions}

blah blah

\subsection{Documentation Conventions}

blah blah

\section{Future of HARK}

HARK is in a state of perpetual incompleteness, always expanding to include more tools and more models.  As an open source project in the hands of many contributors around the world, the HARK team cannot fully predict future features of the toolKit.  This section provides an overview of what we would like to see in the near future, as well as potential mechanisms to encourage researchers to contribute their code to the project.

\subsection{Future Tools}

The current frameworks in \texttt{HARKcore} concern agents who have ``isolated'' dynamic problems or interact with each other only through aggregate outcomes to which they contribute atomically.  We hope to eventually provide a framework for models in which agents directly interact with each other; this may include a system for specifying the state of networks and how connections are formed and broken.  \texttt{HARKcore} might also develop a framework more suited to industrial organization models and dynamic games.\footnote{It might already be possible to shoehorn some of these models into the \texttt{Market} framework.}

The \texttt{HARKestimation} module in particular is very sparsely populated, with its functions mostly serving as wrappers for ``off the shelf'' optimization methods from \texttt{scipy.optimize}.  There are plenty of non-standard or more complex optimization techniques available, including global and/or stochastic search methods.  We believe that additional optimizers are ``low hanging fruit'' as straightforward contributions to HARK and thus will be added in the near future.  Moreover, there are plenty of distributions that have no approximator in \texttt{HARKutilities} (or data generator in \texttt{HARKsimulation}), and these functions are among the easiest for new contributors to write.  The data analysis tools in \texttt{HARKutilities} only include functions that we happened to use for our current research projects, and we expect that this will be the mode of growth for future tools.  There are some obvious holes that we believe will be filled quite quickly; for example, we provide a rudimentary non-parametric kernel regression function, but have not written a kernel density estimator to generate PDFs from data.

The classes currently in \texttt{HARKinterpolation} are all variations on linear (or cubic) spline interpolation, and each is specifically written for a fixed number of dimensions.  As these methods use full tensor grids, they are highly impractical for representing functions in higher dimensions, suffering greatly from the curse of dimensionality.\footnote{The HARK team only included interpolators for up to 4 dimensions, and some would argue this is already too many for tensor grid methods.}  We are quite confident that \texttt{HARKinterpolation} will soon include techniques more applicable to high dimensional state spaces, including Smolnyak interpolation, other (adaptive) sparse grid methods, and regression-based interpolation.  For lower-dimensional spaces, HARK will also soon provide Delaunay interpolation classes.

The \texttt{HARKparallel} module currently provides a simple interface for handling \textit{ex ante} heterogeneity among agents.  While useful for speeding up moderately-sized problems, the libraries used are only able to access the CPU of the local machine running the code.  In the very near future, the HARK team will provide an interface (and example) for using Apache Spark, which bills itself as a ``fast and general engine for large-scale data processing''.  Specifically, users will be able to easily scale up their computing resources and run HARK code on an Amazon EC2 session or other cluster.

\subsection{Future Models}

The economics models currently included in HARK mostly concern consumption-saving problems with constant relative risk aversion consumers who experience fully permanent and fully transitory shocks to income.  This is obviously a very small subset of all consumption-saving models (which are themselves a small subset of all dynamic models economists might be interested in).  Consider some examples of variants, features, and extensions that are not included in HARK, but could be in the future:
\begin{itemize}
\item Consumers with other utility functions, such as CARA or expo-power.

\item Income shocks that are neither fully transitory nor fully permanent.

\item Consumers with a bequest motive or terminal utility function.

\item Utility from leisure and endogenous labor supply.

\item Investment in a durable consumption good such as housing.

\item Exogenous shocks to expenses.

\item Multiple consumption goods, as with endogenous medical care.

\item Portfolio allocation between a risky and riskless asset.

\item Endogenous health evolution and health investment.
\end{itemize}

The HARK team is currently developing a module for mixing discrete and continuous choice models, in the style of Jorgensen, Rust, Iskhakov, and Schjerning (2015).  Among many other models, this framework will enable HARK users to easily develop features like:
\begin{itemize}
\item Labor supply on the extensive margin: the timing of retirement.

\item Selection of job type or sector (by riskiness, specific human capital, etc).

\item Choice of medical insurance contract.

\item Decision to rent or own housing.

\item Endogenous default on debt (with ``macroeconomic'' pricing of debt).

\item Household formation, dissolution, and reproduction.
\end{itemize}

The scope of HARK is limited only by what users choose to put in it.  We hope that within a year of its debut, HARK will include a significant number of canonical models, providing more building blocks for future researchers to create novel combinations and new extensions.

\subsection{Bounty Hunting}

blah blah

\subsection{All Aboard the Ark}

blah blah

\end{document}