{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Asset HANK Model [<cite data-cite=\"6202365/ECL3ZAR7\"></cite>](https://cepr.org/active/publications/discussion_papers/dp.php?dpno=13071) \n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/econ-ark/HARK/BayerLuetticke/notebooks?filepath=HARK%2FBayerLuetticke%2FTwoAsset.ipynb)\n",
    "\n",
    "- Adapted from original slides by Christian Bayer and Ralph Luetticke (Henceforth, 'BL')\n",
    "- Jupyter notebook originally by Seungcheol Lee \n",
    "- Further edits by Chris Carroll, Tao Wang, Edmund Crawley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "BL propose a method for solving Heterogeneous Agent DSGE models that uses fast tools originally employed for image and video compression to speed up a variant of the solution methods proposed by Michael Reiter. <cite data-cite=\"undefined\"></cite>  \n",
    "\n",
    "The Bayer-Luetticke method has the following broad features:\n",
    "   * The model is formulated and solved in discrete time (in contrast with some other recent approaches <cite data-cite=\"6202365/WN76AW6Q\"></cite>)\n",
    "   * Solution begins by calculation of the steady-state equilibrium (StE) with no aggregate shocks\n",
    "   * Both the representation of the consumer's problem and the desciption of the distribution are subjected to a form of \"dimensionality reduction\"\n",
    "      * This means finding a way to represent them efficiently using fewer points\n",
    "   * \"Dimensionality reduction\" of the consumer's decision problem is performed before any further analysis is done\n",
    "      * This involves finding a representation of the policy functions using some class of basis functions\n",
    "   * Dimensionality reduction of the joint distribution is accomplished using a \"copula\"\n",
    "      * See the companion notebook for description of the copula\n",
    "   * The method approximates the business-cycle-induced _deviations_ of the individual policy functions from those that characterize the riskless StE\n",
    "      * This is done using the same basis functions originally optimized to match the StE individual policy function\n",
    "      * The method of capturing dynamic deviations from a reference frame is akin to video compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup \n",
    "\n",
    "#### The Recursive Dynamic Planning Problem\n",
    "\n",
    "BL describe their problem a generic way; here, we will illustrate the meaning of their derivations and notation using the familiar example of the Krusell-Smith model, henceforth KS.  <cite data-cite=\"6202365/VPUXICUR\"></cite>\n",
    "\n",
    "Consider a household problem in presence of aggregate and idiosyncratic risk\n",
    "   * $S_t$ is an (exogenous) aggregate state (e.g., levels of productivity and unemployment)\n",
    "   * $s_{it}$ is a partly endogenous idiosyncratic state (e.g., wealth)\n",
    "   * $\\mu_t$ is the distribution over $s$ at date $t$ (e.g., the wealth distribution)\n",
    "   * $P_{t}$ is the pricing kernel \n",
    "      * It captures the info about the aggregate state that the consumer needs to know in order to behave optimally\n",
    "      * e.g., KS showed that for their problem, a good _approximation_ to $P_{t}$ could be constructed using only $S_{t}$ and the aggregate capital stock $K_{t}$\n",
    "   * $\\Gamma$ defines the budget set\n",
    "      * This delimits the set of feasible choices $x$ that the agent can make\n",
    "      \n",
    "The Bellman equation is:\n",
    "\n",
    "\\begin{equation}\n",
    "        v(s_{it},S_t,\\mu_t) = \\max\\limits_{x \\in \\Gamma(s_{it},P_t)} u(s_{it},x) + \\beta \\mathbb{E}_{t} v(s_{it+1}(x,s_{it}),S_{t+1},\\mu_{t+1})\n",
    "\\end{equation}\n",
    "\n",
    "which, for many types of problems, implies an Euler equation: <!-- Question: Why isn't R a t+1 dated variable (and inside the expectations operator? -->\n",
    "     \\begin{equation}\n",
    "        u^{\\prime}\\left(x(s_{it},S_t,\\mu_t)\\right) = \\beta R(S_t,\\mu_t) \\mathbb{E}_{t} u^{\\prime}\\left(x(s_{it+1},S_{t+1},\\mu_{t+1})\\right)\n",
    "     \\end{equation}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving for the StE \n",
    "\n",
    "The steady-state equilibrium is the one that will come about if there are no aggregate risks (and consumers know this)\n",
    "\n",
    "The first step is to solve for the steady-state:\n",
    "   * Discretize the state space\n",
    "      * Representing the nodes of the discretization in a set of vectors\n",
    "      * Such vectors will be represented by an overbar\n",
    "         * e.g. $\\bar{m}$ is the nodes of cash-on-hand $m$\n",
    "   * The optimal policy $\\newcommand{\\policy}{c}\\newcommand{\\Policy}{C}\\policy(s_{it};P)$ induces flow utility $u_{\\policy}$ whose discretization is a vector $\\bar{u}_{\\bar{\\policy}}$\n",
    "   * Idiosyncratic dynamics are captured by a transition probability matrix $\\Pi_{\\bar{\\policy}}$\n",
    "       * $\\Pi$ is like an expectations operator\n",
    "       * It depends on the vectorization of the policy function $\\bar{\\policy}$\n",
    "   * $P$ is constant because in StE aggregate prices are constant\n",
    "       * e.g., in the KS problem, $P$ would contain the (constant) wage and interest rates\n",
    "   * In StE, the discretized Bellman equation implies\n",
    "     \\begin{equation}\n",
    "        \\bar{v} = \\bar{u} + \\beta \\Pi_{\\bar{\\policy}}\\bar{v}\n",
    "      \\end{equation}\n",
    "     holds for the optimal policy\n",
    "     * A linear interpolator is used to represent the value function\n",
    "   * For the distribution, which (by the definition of steady state) is constant:   \n",
    "\n",
    "\\begin{eqnarray}\n",
    "        \\bar{\\mu} & = & \\bar{\\mu} \\Pi_{\\bar{\\policy}} \\\\\n",
    "        d\\bar{\\mu} & = & d\\bar{\\mu} \\Pi_{\\bar{\\policy}}\n",
    "\\end{eqnarray}\n",
    "     where we differentiate in the second line because we will be representing the distribution as a histogram, which counts the _extra_ population obtained by moving up <!-- Is this right?  $\\mu$ vs $d \\mu$ is a bit confusing.  The d is wrt the state, not time, right? -->\n",
    "     \n",
    "We will define an approximate equilibrium in which:    \n",
    "   * $\\bar{\\policy}$ is the vector that defines a linear interpolating policy function $\\policy$ at the state nodes\n",
    "       * given $P$ and $v$\n",
    "       * $v$ is a linear interpolation of $\\bar{v}$\n",
    "       * $\\bar{v}$ is value at the discretized nodes\n",
    "   * $\\bar{v}$ and $d\\bar{\\mu}$ solve the approximated Bellman equation\n",
    "       * subject to the steady-state constraint\n",
    "   * Markets clear ($\\exists$ joint requirement on $\\bar{\\policy}$, $\\mu$, and $P$; denoted as $\\Phi(\\bar{\\policy}, \\mu, P) = 0$)  <!-- Question: Why is this not $\\bar{\\mu}$ -->\n",
    "\n",
    "This can be solved by:\n",
    "   1. Given $P$, \n",
    "       1. Finding $d\\bar{\\mu}$ as the unit-eigenvalue of $\\Pi_{\\bar{\\policy}}$\n",
    "       2. Using standard solution techniques to solve the micro decision problem\n",
    "          * Like wage and interest rate\n",
    "   2. Using a root-finder to solve for $P$\n",
    "      * This basically iterates the other two steps until it finds values where they are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Introducing aggregate risk\n",
    "\n",
    "With aggregate risk\n",
    "   * Prices $P$ and the distribution $\\mu$ change over time\n",
    "\n",
    "Yet, for the household:\n",
    "   * Only prices and continuation values matter\n",
    "   * The distribution does not influence decisions directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefining equilibrium (Reiter, 2002) \n",
    "A sequential equilibrium with recursive individual planning  <cite data-cite=\"6202365/UKUXJHCN\"></cite> is:\n",
    "   * A sequence of discretized Bellman equations, such that\n",
    "     \\begin{equation}\n",
    "        v_t = \\bar{u}_{P_t} + \\beta \\Pi_{\\policy_t} v_{t+1}\n",
    "     \\end{equation}\n",
    "     holds for policy $\\policy_t$ which optimizes with respect to $v_{t+1}$ and $P_t$\n",
    "   * and a sequence of \"histograms\" (discretized distributions), such that\n",
    "     \\begin{equation}\n",
    "        d\\mu_{t+1} = d\\mu_t \\Pi_{\\policy_t}\n",
    "     \\end{equation}\n",
    "     holds given the policy $h_{t}$, that is optimal given $P_t$, $v_{t+1}$\n",
    "   * Prices, distribution, and policies lead to market clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     6,
     17
    ]
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# This is a jupytext paired notebook that autogenerates a corresponding .py file\n",
    "# which can be executed from a terminal command line via \"ipython [name].py\"\n",
    "# But a terminal does not permit inline figures, so we need to test jupyter vs terminal\n",
    "# Google \"how can I check if code is executed in the ipython notebook\"\n",
    "\n",
    "def in_ipynb():\n",
    "    try:\n",
    "        if str(type(get_ipython())) == \"<class 'ipykernel.zmqshell.ZMQInteractiveShell'>\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "# Determine whether to make the figures inline (for spyder or jupyter)\n",
    "# vs whatever is the automatic setting that will apply if run from the terminal\n",
    "if in_ipynb():\n",
    "    # %matplotlib inline generates a syntax error when run from the shell\n",
    "    # so do this instead\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline') \n",
    "else:\n",
    "    get_ipython().run_line_magic('matplotlib', 'auto') \n",
    "    \n",
    "# The tools for navigating the filesystem\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Find pathname to this file:\n",
    "my_file_path = os.path.dirname(os.path.abspath(\"TwoAsset.ipynb\"))\n",
    "\n",
    "# Relative directory for pickled code\n",
    "code_dir = os.path.join(my_file_path, \"../TwoAssetCode\") \n",
    "\n",
    "sys.path.insert(0, code_dir)\n",
    "sys.path.insert(0, my_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "## Load Stationary equilibrium (StE) object EX3SS_20\n",
    "\n",
    "import pickle\n",
    "os.chdir(code_dir) # Go to the directory with pickled code\n",
    "\n",
    "## EX3SS_20.p is the information in the stationary equilibrium (20: the number of illiquid and liquid weath grids )\n",
    "EX3SS=pickle.load(open(\"EX3SS_20.p\", \"rb\"))\n",
    "\n",
    "## WangTao: Find the code that generates this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compact notation\n",
    "\n",
    "It will be convenient to rewrite the problem using a compact notation proposed by Schmidt-Grohe and Uribe (2004)\n",
    "\n",
    "The equilibrium conditions can be represented as a non-linear difference equation\n",
    "   * Controls: $Y_t = [v_t \\ P_t \\ Z_t^Y]$ and States: $X_t=[\\mu_t \\ S_t \\ Z_t^X]$\n",
    "      * where $Z_t$ are purely aggregate states/controls\n",
    "   * Define <!-- Q: What is $\\epsilon$ here? Why is it not encompassed in S_{t+1}? -->\n",
    "     \\begin{align}\n",
    "      F(d\\mu_t, S_t, d\\mu_{t+1}, S_{t+1}, v_t, P_t, v_{t+1}, P_{t+1}, \\epsilon_{t+1})\n",
    "      &= \\begin{bmatrix}\n",
    "           d\\mu_{t+1} - d\\mu_t\\Pi_{\\policy_t} \\\\\n",
    "           v_t - (\\bar{u}_{\\policy_t} + \\beta \\Pi_{\\policy_t}v_{t+1}) \\\\\n",
    "           S_{t+1} - \\Policy(S_t,d\\mu_t,\\epsilon_{t+1}) \\\\\n",
    "           \\Phi(\\policy_t,d\\mu_t,P_t,S_t) \\\\\n",
    "           \\epsilon_{t+1}\n",
    "           \\end{bmatrix}\n",
    "     \\end{align}\n",
    "     s.t. <!-- Q: Why are S_{t+1} and \\epsilon_{t+1} not arguments of v_{t+1} below? -->\n",
    "     \\begin{equation}\n",
    "     \\policy_t(s_{t}) = \\arg \\max\\limits_{x \\in \\Gamma(s,P_t)} u(s,x) + \\beta \\mathop{\\mathbb{E}_{t}} v_{t+1}(s_{t+1})\n",
    "     \\end{equation}\n",
    "   * The solution is a function-valued difference equation:\n",
    "\\begin{equation}   \n",
    "     \\mathop{\\mathbb{E}_{t}}F(X_t,X_{t+1},Y_t,Y_{t+1},\\epsilon_{t+1}) = 0\n",
    "\\end{equation}    \n",
    "     where $\\mathop{\\mathbb{E}}$ is the expectation over aggregate states\n",
    "   * It becomes real-valued when we replace the functions by their discretized counterparts\n",
    "   * Standard techniques can solve the discretized version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, is all solved?\n",
    "The dimensionality of the system F is a big problem \n",
    "   * With high dimensional idiosyncratic states, discretized value functions and distributions become large objects\n",
    "   * For example:\n",
    "      * 4 income states $\\times$ 100 illiquid capital states $\\times$ 100 liquid capital states $\\rightarrow$ $\\geq$ 40,000 values in $F$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayer-Luetticke method\n",
    "#### Idea:\n",
    "1. Use compression techniques as in video encoding\n",
    "   * Apply a discrete cosine transformation (DCT) to all value/policy functions\n",
    "      * DCT is used because it is the default in the video encoding literature\n",
    "      * Choice of cosine is unimportant; linear basis functions might work just as well\n",
    "   * Represent fluctuations as differences from this reference frame\n",
    "   * Assume all coefficients of the DCT from the StE that are close to zero do not change when there is an aggregate shock (small things stay small)\n",
    "   \n",
    "2. Assume no changes in the rank correlation structure of $\\mu$   \n",
    "   * Calculate the Copula, $\\bar{C}$ of $\\mu$ in the StE\n",
    "   * Perturb only the marginal distributions\n",
    "      * This assumes that the rank correlations remain the same\n",
    "      * See the companion notebook for more discussion of this\n",
    "   * Use fixed Copula to calculate an approximate joint distribution from marginals\n",
    "\n",
    "\n",
    "The approach follows the insight of KS in that it uses the fact that some moments of the distribution do not matter for aggregate dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details\n",
    "1) Compression techniques from video encoding\n",
    "   * Let $\\bar{\\Theta} = dct(\\bar{v})$ be the coefficients obtained from the DCT of the value function in StE\n",
    "   * Define an index set $\\mathop{I}$ that contains the x percent largest (i.e. most important) elements from $\\bar{\\Theta}$\n",
    "   * Let $\\theta$ be a sparse vector with non-zero entries only for elements $i \\in \\mathop{I}$\n",
    "   * Define \n",
    "   \\begin{equation}\n",
    "    \\tilde{\\Theta}(\\theta_t)=\\left\\{\n",
    "      \\begin{array}{@{}ll@{}}\n",
    "         \\bar{\\Theta}(i)+\\theta_t(i), & i \\in \\mathop{I} \\\\\n",
    "         \\bar{\\Theta}(i), & \\text{else}\n",
    "      \\end{array}\\right.\n",
    "   \\end{equation}\n",
    "   * This assumes that the basis functions with least contribution to representation of the function in levels, make no contribution at all to its changes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Decoding\n",
    "   * Now we reconstruct $\\tilde{v}(\\theta_t)=dct^{-1}(\\tilde{\\Theta}(\\theta_{t}))$\n",
    "      * idct=$dct^{-1}$ is the inverse dct that goes from the $\\theta$ vector to the corresponding values\n",
    "   * This means that in the StE the reduction step adds no addtional approximation error:\n",
    "       * Remember that $\\tilde{v}(0)=\\bar{v}$ by construction\n",
    "   * But it allows us to reduce the number of derivatives that need to be calculated from the outset.\n",
    "       * We only calculate derivatives for those basis functions that make an important contribution to the representation of the function\n",
    "   \n",
    "3) The histogram is recovered as follows\n",
    "   * $\\mu_t$ is approximated as $\\bar{C}(\\bar{\\mu_t}^1,...,\\bar{\\mu_t}^n)$, where $n$ is the dimensionality of the idiosyncratic states <!-- Question: Why is there no time subscript on $\\bar{C}$?  I thought the copula was allowed to vary over time ... --> <!-- Question: is $\\mu_{t}$ linearly interpolated between gridpoints? ... -->\n",
    "      * $\\mu_t^{i}$ are the marginal distributions <!-- Question: These are cumulatives, right?  They are not in the same units as $\\mu$ --> \n",
    "   * The StE distribution is obtained when $\\mu = \\bar{C}(\\bar{\\mu}^1,...,\\bar{\\mu}^n)$\n",
    "   * Typically prices are only influenced through the marginal distributions\n",
    "   * The approach ensures that changes in the mass of one state (say, wealth) are distributed in a sensible way across the other dimensions\n",
    "      * Where \"sensible\" means \"like in StE\" <!-- Question: Right? --> \n",
    "   * The implied distributions look \"similar\" to the StE one (different in (Reiter, 2009))\n",
    "\n",
    "4) The large system above is now transformed into a much smaller system:\n",
    "     \\begin{align}\n",
    "      F(\\{d\\mu_t^1,...,d\\mu_t^n\\}, S_t, \\{d\\mu_{t+1}^1,...,d\\mu_{t+1}^n\\}, S_{t+1}, \\theta_t, P_t, \\theta_{t+1}, P_{t+1})\n",
    "      &= \\begin{bmatrix}\n",
    "           d\\bar{C}(\\bar{\\mu}_t^1,...,\\bar{\\mu}_t^n) - d\\bar{C}(\\bar{\\mu}_t^1,...,\\bar{\\mu}_t^n)\\Pi_{\\policy_t} \\\\\n",
    "           dct\\left[idct\\left(\\tilde{\\Theta}(\\theta_t) - (\\bar{u}_{\\policy_t} + \\beta \\Pi_{\\policy_t}idct(\\tilde{\\Theta}(\\theta_{t+1}))\\right)\\right] \\\\\n",
    "           S_{t+1} - \\Policy(S_t,d\\mu_t) \\\\\n",
    "           \\Phi(\\policy_t,d\\mu_t,P_t,S_t) \\\\\n",
    "           \\end{bmatrix}\n",
    "     \\end{align}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two-asset HANK model\n",
    "\n",
    "We illustrate the algorithm in a two-asset HANK model described as below \n",
    "\n",
    "\n",
    "#### Households \n",
    "- Maximizing discounted felicity\n",
    "   - Consumption $c$ \n",
    "      - CRRA coefficent: $\\xi$\n",
    "      - EOS of CES consumption bundle: $\\eta$\n",
    "   - Disutility from work in GHH form: \n",
    "     - Frisch elasticity $\\gamma$\n",
    "- Two assets:\n",
    "   - Liquid nominal bonds $b$, greater than lower bound $\\underline b$\n",
    "      - Borrowing constraint due to a wedge between borrowing and saving rate:  $R^b(b<0)=R^B(b>0)+\\bar R$  \n",
    "   - Illiquid assets capital $k$ nonnegative\n",
    "      - Trading of illiquid assets is subject to a friction governed by $v$, the fraction of agents who can trade\n",
    "      - If nontrading, receive dividend $r$ and depreciates by $\\tau$\n",
    "- Idiosyncratic labor productivity $h$: \n",
    "   - $h = 0$ for entreprener, only receive profits $\\Pi$\n",
    "   - $h = 1$ for labor, evolves according to an autoregressive process, \n",
    "     - $\\rho_h$ persistence parameter\n",
    "     - $\\epsilon^h$: idiosyncratic risk \n",
    "\n",
    "#### Production \n",
    "- Intermediate good producer \n",
    "    - CRS production with TFP $Z$\n",
    "    - Wage $W$\n",
    "    - Cost of capital $r+\\delta$\n",
    "- Reseller \n",
    "    - Rotemberg price setting: quadratic adjustment cost scalled by $\\frac{\\eta}{2\\kappa}$\n",
    "    - Constant discount factor $\\beta$\n",
    "    - Investment subject to Tobin's q adjustment cost $\\phi$ \n",
    "- Aggregate risks $\\Omega$ include \n",
    "   - TFP $Z$, AR(1) process with persistence of $\\rho^Z$ and shock $\\epsilon^Z$  \n",
    "   - Uncertainty \n",
    "   - Monetary policy\n",
    "- Central bank\n",
    "   - Taylor rule on nominal saving rate $R^B$: reacts to deviation of inflation from target by $\\theta_R$ \n",
    "   - $\\rho_R$: policy innertia\n",
    "   - $\\epsilon^R$: monetary policy shocks\n",
    "- Government (fiscal rule)\n",
    "   - Government spending $G$ \n",
    "   - Tax $T$ \n",
    "   - $\\rho_G$: intensity of repaying government debt: $\\rho_G=1$ implies roll-over \n",
    "\n",
    "#### Taking stock\n",
    "\n",
    "- Individual state variables: $\\newcommand{\\liquid}{m}\\liquid$, $k$ and $h$, the joint distribution of individual states $\\Theta$\n",
    "- Individual control variables: $c$, $n$, $\\liquid'$, $k'$ \n",
    "- Optimal policy for adjusters and nonadjusters are $c^*_a$, $n^*_a$ $k^*_a$ and $\\liquid^*_a$ and  $c^*_n$, $n^*_n$ and $\\liquid^*_n$, respectively \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from HARK.BayerLuetticke.TwoAssetCode.FluctuationsTwoAsset import FluctuationsTwoAsset, SGU_solver, plot_IRF\n",
    "\n",
    "start_time0 = time.perf_counter() \n",
    "\n",
    "## Choose an aggregate shock to perturb(one of three shocks: MP, TFP, Uncertainty)\n",
    "\n",
    "# EX3SS['par']['aggrshock']           = 'MP'\n",
    "# EX3SS['par']['rhoS']    = 0.0      # Persistence of variance\n",
    "# EX3SS['par']['sigmaS']  = 0.001    # STD of variance shocks\n",
    "\n",
    "#EX3SS['par']['aggrshock']           = 'TFP'\n",
    "#EX3SS['par']['rhoS']    = 0.95\n",
    "#EX3SS['par']['sigmaS']  = 0.0075\n",
    "    \n",
    "EX3SS['par']['aggrshock']           = 'Uncertainty'\n",
    "EX3SS['par']['rhoS']    = 0.84    # Persistence of variance\n",
    "EX3SS['par']['sigmaS']  = 0.54    # STD of variance shocks\n",
    "\n",
    "\n",
    "## Choose an accuracy of approximation with DCT\n",
    "### Determines number of basis functions chosen -- enough to match this accuracy\n",
    "### EX3SS is precomputed steady-state pulled in above\n",
    "EX3SS['par']['accuracy'] = 0.99999 \n",
    "\n",
    "## Implement state reduction and DCT\n",
    "### Do state reduction on steady state\n",
    "\n",
    "EX3SR=FluctuationsTwoAsset(**EX3SS)\n",
    "SR=EX3SR.StateReduc()\n",
    "\n",
    "print('SGU_solver')\n",
    "SGUresult=SGU_solver(SR['Xss'],SR['Yss'],SR['Gamma_state'],SR['indexMUdct'],SR['indexVKdct'],SR['par'],SR['mpar'],SR['grid'],SR['targets'],SR['Copula'],SR['P_H'],SR['aggrshock'])\n",
    "print('plot_IRF')\n",
    "plot_IRF(SR['mpar'],SR['par'],SGUresult['gx'],SGUresult['hx'],SR['joint_distr'],\n",
    "         SR['Gamma_state'],SR['grid'],SR['targets'],SR['Output'])\n",
    "\n",
    "end_time0 = time.perf_counter()\n",
    "print('Elapsed time is ',  (end_time0-start_time0), ' seconds.')"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "6202365/ECL3ZAR7": {
     "author": [
      {
       "family": "Bayer",
       "given": "Christian"
      },
      {
       "family": "Luetticke",
       "given": "Ralph"
      }
     ],
     "id": "6202365/ECL3ZAR7",
     "issued": {
      "year": 2018
     },
     "note": "bibtex:blSolving",
     "publisher": "CEPR Discussion Papers",
     "title": "Solving heterogeneous agent models in discrete time with many idiosyncratic states by perturbation methods",
     "type": "report"
    },
    "6202365/L5GBWHBM": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "undefined",
     "issue": "1",
     "issued": {
      "month": 1,
      "year": 2010
     },
     "note": "Citation Key: reiterBackward",
     "page": "28-35",
     "page-first": "28",
     "title": "Solving the Incomplete Markets Model with Aggregate Uncertainty by Backward Induction",
     "type": "article-journal",
     "volume": "34"
    },
    "6202365/UKUXJHCN": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "id": "6202365/UKUXJHCN",
     "note": "Citation Key: reiter2002recursive \nbibtex*[publisher=Citeseer]",
     "title": "Recursive computation of heterogeneous agent models",
     "type": "article-journal"
    },
    "6202365/VPUXICUR": {
     "author": [
      {
       "family": "Krusell",
       "given": "Per"
      },
      {
       "family": "Smith",
       "given": "Anthony A."
      }
     ],
     "container-title": "Journal of Political Economy",
     "id": "6202365/VPUXICUR",
     "issue": "5",
     "issued": {
      "year": 1998
     },
     "page": "867â€“896",
     "page-first": "867",
     "title": "Income and Wealth Heterogeneity in the Macroeconomy",
     "type": "article-journal",
     "volume": "106"
    },
    "6202365/WN76AW6Q": {
     "author": [
      {
       "family": "SeHyoun Ahn, Greg Kaplan, Benjamin Moll, Thomas Winberry",
       "given": ""
      },
      {
       "family": "Wolf",
       "given": "Christian"
      }
     ],
     "editor": [
      {
       "family": "Parker",
       "given": "Jonathan"
      },
      {
       "family": "Martin S. Eichenbaum",
       "given": "Organizers"
      }
     ],
     "id": "6202365/WN76AW6Q",
     "issued": {
      "year": 2017
     },
     "note": "Citation Key: akmwwInequality \nbibtex*[booktitle=NBER Macroeconomics Annual;publisher=MIT Press;location=Cambridge, MA]",
     "title": "When Inequality Matters for Macro and Macro Matters for Inequality",
     "type": "article-journal",
     "volume": "32"
    },
    "undefined": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "undefined",
     "issue": "1",
     "issued": {
      "month": 1,
      "year": 2010
     },
     "note": "Citation Key: reiterBackward",
     "page": "28-35",
     "page-first": "28",
     "title": "Solving the Incomplete Markets Model with Aggregate Uncertainty by Backward Induction",
     "type": "article-journal",
     "volume": "34"
    }
   }
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
